# Flink-20663

### Link: 

https://issues.apache.org/jira/browse/FLINK-20663?focusedCommentId=17272763&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17272763

### Bug category

​		OOM

### Bug trigger

​		Widely exists. Normal batch job will trigger this problem.

​		Some batch **operators** (**join**, **group_by**) **are** **chained** together.

```python
# bug script(summary.py) provided by the reporter
group_result = material_full_table.group_by(material_full_table.group_key, material_full_table.subtypeid)
...
result = show_result.left_outer_join(click_result, show_result.show_group_key == click_result.click_group_key)
```

​		The **cluster load** is a bit **heavy**.

​			

### Root cause

​	For **batch jobs**, there will be much more **frequent memory allocation/free**. It will cause much more **full GC**(全量回收), sometimes it will throw **OOM** exception if **JVM can't free the memory** enough quickly, finally it triggers unnecessary job failure.

​	https://issues.apache.org/jira/browse/FLINK-20663?focusedCommentId=17272763&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17272763

### Consequence

​	Batch / streaming jobs failure.

### Fix

https://github.com/apache/flink/commit/1f8be1fd7b2b37a124e4d2b8080d08e259bdf095

<img src="/Users/qwb/Library/Application Support/typora-user-images/image-20250319173634319.png" alt="image-20250319173634319" style="zoom:50%;" />

- Release unsafe memory instantly on segments freed by introducing `cleaner`.

  - <img src="/Users/qwb/Library/Application Support/typora-user-images/image-20250319174158245.png" alt="image-20250319174158245" style="zoom: 50%;" />

  - <img src="/Users/qwb/Library/Application Support/typora-user-images/image-20250319174243336.png" alt="image-20250319174243336" style="zoom: 50%;" />

### Log

**1229** lines in total

```shell
2021-04-07 19:01:27,427 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e).
2021-04-07 19:01:27,435 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 acc0759fada1f8a28b8fe4d6fba40d2e.
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df).
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) switched from RUNNING to CANCELING.
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df).
2021-04-07 19:01:27,678 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1).
2021-04-07 19:01:27,679 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 is already in state FAILED
2021-04-07 19:01:27,677 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) switched from RUNNING to FAILED.
java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining.
This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.

org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2] at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
```

### LLM prompt

Prompt input:

```shell
The following are logs from flink task manager.
Do you find any evidence of a calling relationship between functions or processes?
 - Say ‘YES:{functions/processes}’ if you detect a relationship in the log
 - Say ‘NO:{INDEX}’ if there is no relationship
```

#### Reason about relationship between task manager and jvm gc

```
Question:
	do you consider jvm level? If not, why

ChatGPT said:
You're absolutely right to ask about the JVM level, and I didn't specifically address it in my previous responses. To clarify, at the JVM level, the relationships between components are more focused on how Java classes and objects interact during the execution of the Flink and YARN processes, including memory management, task execution, and resource allocation.

Why JVM Level Relationships Matter:
When we discuss the relationships at the JVM level, we're considering:

Object Interactions: How instances of classes (e.g., ActiveResourceManager, YarnResourceManagerDriver, TaskManager, SlotPool) interact by invoking methods on each other and managing the flow of resources.

Concurrency & Threading: How the JVM manages multithreading, especially with tasks being executed in parallel across TaskManagers.

Memory Management: How memory is allocated for different components, such as the TaskExecutor containers and the memory used by Flink’s operators, which can involve both heap and off-heap memory.

Garbage Collection: How the JVM's garbage collector handles unused objects, especially in the context of Flink’s resource management where objects like task slots, containers, and memory buffers need to be efficiently managed and cleaned up.

JVM Communication: How JVM components communicate with each other, such as through Java RMI (Remote Method Invocation) for Flink’s internal networking (e.g., TaskManager to JobMaster communication).

Programming-Level Relationships Already Considered:
In the previous response, I focused on programming-level relationships at the API level within the application logic (Flink and YARN). These relationships involve:

API calls and method invocations across modules.

Component interactions, like how TaskManagers request resources from ResourceManagers, and how the JobMaster schedules tasks for execution on TaskManagers.

These interactions all occur within the JVM runtime, where Java objects are created, stored in memory (heap or off-heap), and managed by Java’s garbage collector. However, I did not delve into JVM-specific details such as JVM garbage collection, threading, or memory management within the JVM itself (e.g., heap vs. off-heap, stack vs. heap memory, etc.).

JVM-Level Considerations That I Did Not Explicitly Discuss:
Memory Management: The MemoryManager class in Flink deals with memory allocation at a very low level, both in terms of heap and off-heap memory. It may directly interact with the JVM’s native memory management, especially for off-heap memory, which is used for things like caching, state backends (e.g., RocksDB), and buffers. This could involve the Unsafe class or DirectByteBuffer for off-heap allocations.

Relationship: JVM-level memory management in the context of off-heap storage involves native memory management outside the JVM heap. For example, the MemoryManager directly manages memory allocations outside the Java heap space to avoid pressure on garbage collection, improving performance for high-throughput tasks.

Concurrency: Flink’s task scheduling and execution involve multithreading in the JVM. Tasks within the TaskManager are executed on different threads, and communication between components (e.g., JobMaster, ResourceManager, and TaskManager) uses asynchronous messaging (e.g., through Flink’s Akka actor system or Flink’s RpcEndpoint for remote communication).

Relationship: JVM threads are used for concurrent task execution. TaskManager threads perform processing, while JobMaster manages task scheduling asynchronously. The JVM’s threading model, including thread synchronization and thread safety, is crucial for managing the parallel execution of tasks in a distributed environment like Flink.

Garbage Collection (GC): Java’s garbage collection in Flink is vital, especially in scenarios where objects are frequently created and discarded, like task execution in TaskManagers. For Flink’s managed memory, the off-heap memory (used in operators or state backends) is not subject to garbage collection, but objects stored in the heap are.

Relationship: Managed memory (off-heap) is not collected by the JVM's garbage collector, so explicit memory management is necessary. JVM garbage collection only cleans up objects on the heap (i.e., Flink’s regular Java objects) and must be carefully managed to prevent excessive pauses or memory overhead.

JVM Networking: Communication between TaskManagers and JobMaster, or between ResourceManager and TaskManager, typically uses Java networking APIs like RMI (Remote Method Invocation) or Akka actors for asynchronous communication.

Relationship: JVM-level communication (via networking) involves the Java networking stack, and message passing often occurs through Akka actors or gRPC in Flink, which operate within the JVM. The network communication ensures that Flink’s distributed components can interact across nodes in the cluster.

Why I Didn't Initially Address JVM-Level Relationships:
The JVM-level relationships are often more granular and involve the underlying system (e.g., memory management, threading, garbage collection) that supports the higher-level component interactions. These details are essential for performance tuning and managing resource consumption, but they are not typically captured in the general component-level API interactions unless the context specifically delves into performance or memory management issues.

In summary, while the previous explanation focused on API-level interactions between Flink components and YARN at a higher level, JVM-level relationships (such as memory management, concurrency, and garbage collection) are important when considering resource efficiency, parallelism, and low-latency task execution. These JVM-level details are implicit in the component interactions, but they can also be crucial for fine-tuning and optimizing the system's performance.
```



### LLM output

Output from GPT 4o:

```shell
YES: The log indicates a relationship between the HashJoin, Calc, and Expand processes. 
These processes are part of a sequence of operations within a task, and there is evidence of function calls between them, 
such as the use of HashJoin followed by Calc and Expand transformations in a data processing pipeline.
```



### Comparison experiment