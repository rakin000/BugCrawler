021-04-07 19:14:17,049 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{e9a1663595b65543531376809b3ec571}] and profile ResourceProfile{UNKNOWN} with allocation id b4063d98a5288887fa53a829571520d0 from resource manager.
2021-04-07 19:14:17,049 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{64d064f38b220446e995b38d2fd06b64}] and profile ResourceProfile{UNKNOWN} with allocation id 9c41c1d1c2f1d6d4595a27d228394493 from resource manager.
2021-04-07 19:14:17,050 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{23d5b0e5025f60eb1291ff0e87e3781b}] and profile ResourceProfile{UNKNOWN} with allocation id 5776a372bec5d4048805194bb91946e9 from resource manager.
2021-04-07 19:14:17,050 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3ce3467c8767d6f57a1163817536cd7d}] and profile ResourceProfile{UNKNOWN} with allocation id 4c99269a322dd54af88720da987887a3 from resource manager.
2021-04-07 19:14:17,051 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{95b9d171c21c8a1f09fb763dd4434883}] and profile ResourceProfile{UNKNOWN} with allocation id e58eec0e6351ccfbcbc876480a843a87 from resource manager.
2021-04-07 19:14:17,051 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{052dd14100c1e0948d1f50061c508fbb}] and profile ResourceProfile{UNKNOWN} with allocation id 32522b8210013182c4a072c2d3ffa963 from resource manager.
2021-04-07 19:14:17,052 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1d7ccda85171dd75b033157e36e531c7}] and profile ResourceProfile{UNKNOWN} with allocation id 7097ce1a54eedf97297f9904cc2a0365 from resource manager.
2021-04-07 19:14:17,052 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{43649b2a648f4b57130c0facd0ac13db}] and profile ResourceProfile{UNKNOWN} with allocation id 9c5e2d2f4e8c6bb0fbef7bb483614daa from resource manager.
2021-04-07 19:14:17,053 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{822eaf8de983b6c262915480bf293042}] and profile ResourceProfile{UNKNOWN} with allocation id e7e2794f16c496b733c0260bf0ab4914 from resource manager.
2021-04-07 19:14:17,053 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{a1218660365238b3422aff4867d7a4d8}] and profile ResourceProfile{UNKNOWN} with allocation id 54d70d868a9bd9fcbf10eabad186615f from resource manager.
2021-04-07 19:14:17,054 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{5b0a156ed1c9111a21aff9374e8b1191}] and profile ResourceProfile{UNKNOWN} with allocation id f59532e377b93e6c52dcbd0af2f1f976 from resource manager.
2021-04-07 19:14:17,055 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 1.
2021-04-07 19:14:17,075 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:17,078 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id b4063d98a5288887fa53a829571520d0.
2021-04-07 19:14:17,078 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 9c41c1d1c2f1d6d4595a27d228394493.
2021-04-07 19:14:17,078 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 5776a372bec5d4048805194bb91946e9.
2021-04-07 19:14:17,079 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 2.
2021-04-07 19:14:17,079 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:17,080 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 4c99269a322dd54af88720da987887a3.
2021-04-07 19:14:17,080 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id e58eec0e6351ccfbcbc876480a843a87.
2021-04-07 19:14:17,080 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 32522b8210013182c4a072c2d3ffa963.
2021-04-07 19:14:17,080 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 3.
2021-04-07 19:14:17,081 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:17,081 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 7097ce1a54eedf97297f9904cc2a0365.
2021-04-07 19:14:17,082 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 9c5e2d2f4e8c6bb0fbef7bb483614daa.
2021-04-07 19:14:17,082 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id e7e2794f16c496b733c0260bf0ab4914.
2021-04-07 19:14:17,083 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 4.
2021-04-07 19:14:17,083 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:17,083 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 54d70d868a9bd9fcbf10eabad186615f.
2021-04-07 19:14:17,084 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id f59532e377b93e6c52dcbd0af2f1f976.
2021-04-07 19:14:22,332 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 2 containers.
2021-04-07 19:14:22,334 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 2 containers with priority 1, 4 pending container requests.
2021-04-07 19:14:22,342 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Removing container request Capability[<memory:46789, vCores:3>]Priority[1]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null].
2021-04-07 19:14:22,342 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - TaskExecutor container_e06_1616661788395_0878_01_000002(sdl-hadoop2.test.com:8041) will be started on sdl-hadoop2.test.com with TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}.
2021-04-07 19:14:22,342 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Removing container request Capability[<memory:46789, vCores:3>]Priority[1]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null].
2021-04-07 19:14:22,342 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Accepted 2 requested containers, returned 0 excess containers, 2 pending container requests of resource <memory:46789, vCores:3>.
2021-04-07 19:14:22,343 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - TaskExecutor container_e06_1616661788395_0878_01_000003(sdl-hadoop1.test.com:8041) will be started on sdl-hadoop1.test.com with TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}.
2021-04-07 19:14:22,372 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Creating container launch context for TaskManagers
2021-04-07 19:14:22,372 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Creating container launch context for TaskManagers
2021-04-07 19:14:22,376 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Starting TaskManagers
2021-04-07 19:14:22,376 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Starting TaskManagers
2021-04-07 19:14:22,405 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requested worker container_e06_1616661788395_0878_01_000002(sdl-hadoop2.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}.
2021-04-07 19:14:22,405 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requested worker container_e06_1616661788395_0878_01_000003(sdl-hadoop1.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}.
2021-04-07 19:14:22,406 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Processing Event EventType: START_CONTAINER for Container container_e06_1616661788395_0878_01_000002
2021-04-07 19:14:22,406 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Processing Event EventType: START_CONTAINER for Container container_e06_1616661788395_0878_01_000003
2021-04-07 19:14:22,835 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 1 containers.
2021-04-07 19:14:22,835 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 1 containers with priority 1, 2 pending container requests.
2021-04-07 19:14:22,836 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Removing container request Capability[<memory:46789, vCores:3>]Priority[1]AllocationRequestId[0]ExecutionTypeRequest[{Execution Type: GUARANTEED, Enforce Execution Type: false}]Resource Profile[null].
2021-04-07 19:14:22,836 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Accepted 1 requested containers, returned 0 excess containers, 1 pending container requests of resource <memory:46789, vCores:3>.
2021-04-07 19:14:22,836 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - TaskExecutor container_e06_1616661788395_0878_01_000004(sdl-hadoop3.test.com:8041) will be started on sdl-hadoop3.test.com with TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}.
2021-04-07 19:14:22,841 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Creating container launch context for TaskManagers
2021-04-07 19:14:22,843 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Starting TaskManagers
2021-04-07 19:14:22,845 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requested worker container_e06_1616661788395_0878_01_000004(sdl-hadoop3.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}.
2021-04-07 19:14:22,846 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Processing Event EventType: START_CONTAINER for Container container_e06_1616661788395_0878_01_000004
2021-04-07 19:14:27,565 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering TaskManager with ResourceID container_e06_1616661788395_0878_01_000002(sdl-hadoop2.test.com:8041) (akka.tcp://flink@sdl-hadoop2.test.com:6485/user/rpc/taskmanager_0) at ResourceManager
2021-04-07 19:14:27,601 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000002(sdl-hadoop2.test.com:8041) is registered.
2021-04-07 19:14:27,602 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000002(sdl-hadoop2.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)} was requested in current attempt. Current pending count after registering: 3.
2021-04-07 19:14:27,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3) (df7e0e5506d50200874bb915f9ce739b) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:27,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3) (attempt #0) with attempt id df7e0e5506d50200874bb915f9ce739b to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:27,704 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3) (786e441f3cd9f31f21429044090af57e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:27,704 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3) (attempt #0) with attempt id 786e441f3cd9f31f21429044090af57e to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:27,704 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3) (a0d91bdfa1f72c7416ee9b92d09a6d3d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:27,705 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3) (attempt #0) with attempt id a0d91bdfa1f72c7416ee9b92d09a6d3d to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:27,914 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3) (df7e0e5506d50200874bb915f9ce739b) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:27,915 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3) (786e441f3cd9f31f21429044090af57e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:27,916 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3) (a0d91bdfa1f72c7416ee9b92d09a6d3d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:29,948 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering TaskManager with ResourceID container_e06_1616661788395_0878_01_000004(sdl-hadoop3.test.com:8041) (akka.tcp://flink@sdl-hadoop3.test.com:31734/user/rpc/taskmanager_0) at ResourceManager
2021-04-07 19:14:29,973 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000004(sdl-hadoop3.test.com:8041) is registered.
2021-04-07 19:14:29,973 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000004(sdl-hadoop3.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)} was requested in current attempt. Current pending count after registering: 2.
2021-04-07 19:14:30,053 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3) (ce36706c1bffcc41ba3e618665be5ca1) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,053 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3) (attempt #0) with attempt id ce36706c1bffcc41ba3e618665be5ca1 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:30,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3) (40320f90d98b6dfdfe04c2f25f6b9ffa) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3) (attempt #0) with attempt id 40320f90d98b6dfdfe04c2f25f6b9ffa to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:30,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3) (d3800954e0430245c3a625e2bfbe892f) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3) (attempt #0) with attempt id d3800954e0430245c3a625e2bfbe892f to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:30,258 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3) (d3800954e0430245c3a625e2bfbe892f) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,260 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3) (40320f90d98b6dfdfe04c2f25f6b9ffa) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,261 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3) (ce36706c1bffcc41ba3e618665be5ca1) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,261 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering TaskManager with ResourceID container_e06_1616661788395_0878_01_000003(sdl-hadoop1.test.com:8041) (akka.tcp://flink@sdl-hadoop1.test.com:10994/user/rpc/taskmanager_0) at ResourceManager
2021-04-07 19:14:30,281 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000003(sdl-hadoop1.test.com:8041) is registered.
2021-04-07 19:14:30,281 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e06_1616661788395_0878_01_000003(sdl-hadoop1.test.com:8041) with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)} was requested in current attempt. Current pending count after registering: 1.
2021-04-07 19:14:30,349 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3) (07102f808e0eb210a1b2eabf7e2d1815) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,350 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3) (attempt #0) with attempt id 07102f808e0eb210a1b2eabf7e2d1815 to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id 32522b8210013182c4a072c2d3ffa963
2021-04-07 19:14:30,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3) (b77b89626d62412743d18fac1233e404) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3) (attempt #0) with attempt id b77b89626d62412743d18fac1233e404 to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id 3ccf514ce75c115dfb1451e7122e46f2
2021-04-07 19:14:30,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3) (30eebfce7ec8a3d33d9d262ec4ef8aa8) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3) (attempt #0) with attempt id 30eebfce7ec8a3d33d9d262ec4ef8aa8 to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id f59532e377b93e6c52dcbd0af2f1f976
2021-04-07 19:14:30,539 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3) (30eebfce7ec8a3d33d9d262ec4ef8aa8) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,540 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3) (07102f808e0eb210a1b2eabf7e2d1815) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,542 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3) (b77b89626d62412743d18fac1233e404) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,777 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3) (d3800954e0430245c3a625e2bfbe892f) switched from RUNNING to FINISHED.
2021-04-07 19:14:30,780 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3) (ca80c5654ea6bbd70d42ff14a4ddb814) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,780 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3) (attempt #0) with attempt id ca80c5654ea6bbd70d42ff14a4ddb814 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:30,785 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3) (40320f90d98b6dfdfe04c2f25f6b9ffa) switched from RUNNING to FINISHED.
2021-04-07 19:14:30,786 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3) (e7153f17913870a051f4b095071e1c1c) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,786 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3) (attempt #0) with attempt id e7153f17913870a051f4b095071e1c1c to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:30,798 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3) (ca80c5654ea6bbd70d42ff14a4ddb814) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,806 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3) (e7153f17913870a051f4b095071e1c1c) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,834 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3) (e7153f17913870a051f4b095071e1c1c) switched from RUNNING to FINISHED.
2021-04-07 19:14:30,835 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3) (5bde70eebf4a96ba83f1dab66e3ce0e3) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:30,835 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3) (attempt #0) with attempt id 5bde70eebf4a96ba83f1dab66e3ce0e3 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:30,850 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3) (5bde70eebf4a96ba83f1dab66e3ce0e3) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:30,868 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3) (5bde70eebf4a96ba83f1dab66e3ce0e3) switched from RUNNING to FINISHED.
2021-04-07 19:14:31,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3) (ca80c5654ea6bbd70d42ff14a4ddb814) switched from RUNNING to FINISHED.
2021-04-07 19:14:31,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3) (ce36706c1bffcc41ba3e618665be5ca1) switched from RUNNING to FINISHED.
2021-04-07 19:14:47,119 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,120 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop2': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,129 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 2 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,129 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 0 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,129 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop2': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,130 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 0 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,343 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 1 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,344 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop2': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,346 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 1 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,560 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 1 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,560 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop2': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,561 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 1 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=, partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}
2021-04-07 19:14:47,592 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 0 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,594 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 0
2021-04-07 19:14:47,594 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,594 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 2
2021-04-07 19:14:47,681 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 1 (on host 'sdl-hadoop2.test.com') is requesting a file source split
2021-04-07 19:14:47,682 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 1
2021-04-07 19:14:49,505 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3) (786e441f3cd9f31f21429044090af57e) switched from RUNNING to FINISHED.
2021-04-07 19:14:49,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3) (df7e0e5506d50200874bb915f9ce739b) switched from RUNNING to FINISHED.
2021-04-07 19:14:49,620 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3) (a0d91bdfa1f72c7416ee9b92d09a6d3d) switched from RUNNING to FINISHED.
2021-04-07 19:14:49,621 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (438ab3062f675a860a3f4dee2d1576b2) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,625 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (438ab3062f675a860a3f4dee2d1576b2) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,625 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id 438ab3062f675a860a3f4dee2d1576b2 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:49,627 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (db65b2d84052222a8357780af5f5c90b) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,628 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (db65b2d84052222a8357780af5f5c90b) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,628 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id db65b2d84052222a8357780af5f5c90b to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:49,629 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (5d7604bf660b1ac8c47a3b55d81730fd) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,629 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (5d7604bf660b1ac8c47a3b55d81730fd) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,629 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 5d7604bf660b1ac8c47a3b55d81730fd to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:49,630 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (9a3d214ac7708aa56329f14b0d15b2e3) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,630 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (9a3d214ac7708aa56329f14b0d15b2e3) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,630 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id 9a3d214ac7708aa56329f14b0d15b2e3 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:49,631 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (b2b1c3de06970cb3bbc743dcf1ea9646) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,631 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (b2b1c3de06970cb3bbc743dcf1ea9646) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,632 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id b2b1c3de06970cb3bbc743dcf1ea9646 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:49,632 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (bfe9d6f5556b9f5deb6f7596e7671d85) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,633 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (bfe9d6f5556b9f5deb6f7596e7671d85) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:49,633 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id bfe9d6f5556b9f5deb6f7596e7671d85 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:49,633 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a3f9c2a6b546bdfaed3d035a8e8f0e56) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,634 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{bfc64eb7f1d51c1a8c1a3173eb4de581}] and profile ResourceProfile{UNKNOWN} with allocation id cccc37c1448ab11c156839596548f2f7 from resource manager.
2021-04-07 19:14:49,634 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (cb9e9b59974fe11160f51c1a3342d74d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,634 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id cccc37c1448ab11c156839596548f2f7.
2021-04-07 19:14:49,635 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{de323057bb58daa203a110dd1ae71383}] and profile ResourceProfile{UNKNOWN} with allocation id d57c600e910e2433ebbfa90573f1ec8f from resource manager.
2021-04-07 19:14:49,635 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id d57c600e910e2433ebbfa90573f1ec8f.
2021-04-07 19:14:49,636 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (70b2cc59da09922efe658b51d219519a) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,636 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{2c06905366e88b5674ef2a56d2274862}] and profile ResourceProfile{UNKNOWN} with allocation id 18e39b2e94c7c0ed35cb5c6d2574d3a3 from resource manager.
2021-04-07 19:14:49,637 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 18e39b2e94c7c0ed35cb5c6d2574d3a3.
2021-04-07 19:14:49,637 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (b77dc530216c8eb6addad3051f083efa) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,638 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{626f1c91275ab4c8f6725c0633dbdf6e}] and profile ResourceProfile{UNKNOWN} with allocation id b36be69325f5946f90ab3d1e07befb9c from resource manager.
2021-04-07 19:14:49,638 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d68d0f2f1c13f9c8934931c0a8034fdf) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,639 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id b36be69325f5946f90ab3d1e07befb9c.
2021-04-07 19:14:49,639 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{ea53c61bbbec0576b807786b28ffed96}] and profile ResourceProfile{UNKNOWN} with allocation id 6de528d52a4f1b81067f68a66620e259 from resource manager.
2021-04-07 19:14:49,639 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 2.
2021-04-07 19:14:49,639 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (4688694675f239e4f9fab0e028c1e0c4) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,640 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{6420cbf1d62f34ae00f2ac10916813a9}] and profile ResourceProfile{UNKNOWN} with allocation id acdf9d454a34d52b8731c5014e0b6a29 from resource manager.
2021-04-07 19:14:49,639 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,640 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6de528d52a4f1b81067f68a66620e259.
2021-04-07 19:14:49,640 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a490714eead0e4b8ffa99c98c2b48677) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,640 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id acdf9d454a34d52b8731c5014e0b6a29.
2021-04-07 19:14:49,641 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{8a4a46a505ed99c73455ed4bbb631e41}] and profile ResourceProfile{UNKNOWN} with allocation id 44a28a73bd688005dbbbe6924d266f1f from resource manager.
2021-04-07 19:14:49,641 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 44a28a73bd688005dbbbe6924d266f1f.
2021-04-07 19:14:49,641 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 3.
2021-04-07 19:14:49,641 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e0d87c57c0ad667b43cbe79d04c8460e) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,642 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{78793fd68631bb73cc1a94b87229a94f}] and profile ResourceProfile{UNKNOWN} with allocation id 704980c21d84237c3615bd354190ce77 from resource manager.
2021-04-07 19:14:49,642 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9e20ae2809e67cfc571ef30dd017acaf) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,642 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,643 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 704980c21d84237c3615bd354190ce77.
2021-04-07 19:14:49,643 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{87770e8271e30479e72e80399932c775}] and profile ResourceProfile{UNKNOWN} with allocation id 36a6108e79e12ee9fde9387f791675ba from resource manager.
2021-04-07 19:14:49,643 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 36a6108e79e12ee9fde9387f791675ba.
2021-04-07 19:14:49,643 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (3003f59ed8849d9c3c5e1254a8066a68) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,644 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{9d2504b38b8cdfd60a227ac749c84ad9}] and profile ResourceProfile{UNKNOWN} with allocation id c60c34d6aaf72d543aa0c3cc40f91253 from resource manager.
2021-04-07 19:14:49,644 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c60c34d6aaf72d543aa0c3cc40f91253.
2021-04-07 19:14:49,644 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 4.
2021-04-07 19:14:49,644 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e3bded0698f8813f75f1df0dd8cf09b0) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,644 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,645 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{cc7991cc3a8941b783381e785dac1e2d}] and profile ResourceProfile{UNKNOWN} with allocation id 6fccb09b264c0024936f55d3786835c0 from resource manager.
2021-04-07 19:14:49,645 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6fccb09b264c0024936f55d3786835c0.
2021-04-07 19:14:49,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (e8e0fbebc80df857700dcc1f12ca6fe1) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,646 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{fbeafdbc793ad424c3b305d15ba11778}] and profile ResourceProfile{UNKNOWN} with allocation id 87d1b2f6a7cb24b38e56380390114ac6 from resource manager.
2021-04-07 19:14:49,646 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 87d1b2f6a7cb24b38e56380390114ac6.
2021-04-07 19:14:49,646 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (dc7e6f136dd35c124f011b28ed7605cd) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,646 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{51f7cd50a40f158c0b8264c2a03dc727}] and profile ResourceProfile{UNKNOWN} with allocation id 486d527ce9bf1d631f4a0ec657fb1718 from resource manager.
2021-04-07 19:14:49,647 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 486d527ce9bf1d631f4a0ec657fb1718.
2021-04-07 19:14:49,647 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 5.
2021-04-07 19:14:49,647 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d5eaff0899e9df32bdb85f08344b6914) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,647 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,647 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{e462de1b89e6932a07a174048a063aec}] and profile ResourceProfile{UNKNOWN} with allocation id 38cffffff7b8c080c1b4395ef4b8ee8d from resource manager.
2021-04-07 19:14:49,648 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 38cffffff7b8c080c1b4395ef4b8ee8d.
2021-04-07 19:14:49,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (f40a7ca01712e515fb1b77111e6e49ac) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,648 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{e1d363fbbb3ecc28fc2817b9e016f935}] and profile ResourceProfile{UNKNOWN} with allocation id 17e39c60c8e4a5e52359d7ffaecdd67c from resource manager.
2021-04-07 19:14:49,648 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 17e39c60c8e4a5e52359d7ffaecdd67c.
2021-04-07 19:14:49,649 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (200fd15c5e115272ff000bbc3252e7c0) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,649 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{a1f4074e906294bf46dd15c98ca8d259}] and profile ResourceProfile{UNKNOWN} with allocation id 6e7a046a9edf1079cc036fbc05ec208b from resource manager.
2021-04-07 19:14:49,649 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6e7a046a9edf1079cc036fbc05ec208b.
2021-04-07 19:14:49,649 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 6.
2021-04-07 19:14:49,650 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (48df6e6e45d5b04de99199591aec46f7) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,650 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,650 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3c5d432c39ef91f2d81ae9f9bdb7478e}] and profile ResourceProfile{UNKNOWN} with allocation id 88021d9a8842dc16747c91a4a3dd11ce from resource manager.
2021-04-07 19:14:49,650 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 88021d9a8842dc16747c91a4a3dd11ce.
2021-04-07 19:14:49,650 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9ed7345283df21a584c9c51d03df3f65) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,651 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{36501fc55b2e5c4e2e7117b0ec970b4b}] and profile ResourceProfile{UNKNOWN} with allocation id ad10307e7612f7b65375fadd20a9a26a from resource manager.
2021-04-07 19:14:49,651 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id ad10307e7612f7b65375fadd20a9a26a.
2021-04-07 19:14:49,651 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (13019389ef531c8ecd98ddb0022eb368) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,652 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{39a5b9bf96057288fd0832a69132f8de}] and profile ResourceProfile{UNKNOWN} with allocation id b062cfe1827df61d87082d2816bfb30d from resource manager.
2021-04-07 19:14:49,652 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id b062cfe1827df61d87082d2816bfb30d.
2021-04-07 19:14:49,652 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (fdf8686770eae277fac69231213bc5b7) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,652 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=3.0, taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemSize=17.777gb (19087858358 bytes)}, current pending count: 7.
2021-04-07 19:14:49,652 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{551d8b9eadf0f77767d5fb31a5155550}] and profile ResourceProfile{UNKNOWN} with allocation id 3ce10e295fafe1cec3c7c5ae8d6b75b2 from resource manager.
2021-04-07 19:14:49,652 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=3.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=25.415gb (27289609546 bytes), taskOffHeapSize=0 bytes, networkMemSize=1024.000mb (1073741824 bytes), managedMemorySize=17.777gb (19087858358 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=1024.000mb (1073741824 bytes)}, priority 1.
2021-04-07 19:14:49,653 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 3ce10e295fafe1cec3c7c5ae8d6b75b2.
2021-04-07 19:14:49,653 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (2f2d1e3ed33df21669e27982739c66d4) switched from CREATED to SCHEDULED.
2021-04-07 19:14:49,653 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{914493d97559c39cadcd25b0cf216d99}] and profile ResourceProfile{UNKNOWN} with allocation id 5d9b5b416e41e29b3edde54742ce8d5f from resource manager.
2021-04-07 19:14:49,653 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 5d9b5b416e41e29b3edde54742ce8d5f.
2021-04-07 19:14:49,674 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (438ab3062f675a860a3f4dee2d1576b2) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:49,675 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (db65b2d84052222a8357780af5f5c90b) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:49,679 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (5d7604bf660b1ac8c47a3b55d81730fd) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:49,685 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (9a3d214ac7708aa56329f14b0d15b2e3) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:49,687 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (b2b1c3de06970cb3bbc743dcf1ea9646) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:49,687 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (bfe9d6f5556b9f5deb6f7596e7671d85) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,101 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (bfe9d6f5556b9f5deb6f7596e7671d85) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a3f9c2a6b546bdfaed3d035a8e8f0e56) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id a3f9c2a6b546bdfaed3d035a8e8f0e56 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,104 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (9a3d214ac7708aa56329f14b0d15b2e3) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,104 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (cb9e9b59974fe11160f51c1a3342d74d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,104 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id cb9e9b59974fe11160f51c1a3342d74d to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,106 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (b2b1c3de06970cb3bbc743dcf1ea9646) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,106 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (70b2cc59da09922efe658b51d219519a) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,106 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 70b2cc59da09922efe658b51d219519a to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,112 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (ce595a07c1e072c2f9e289443dd5b83f) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,112 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{2e793bf6a5116f3c4dfcca65768f8464}] and profile ResourceProfile{UNKNOWN} with allocation id 46054e6594a5dd168f5b5bc569c9a43c from resource manager.
2021-04-07 19:14:50,112 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 46054e6594a5dd168f5b5bc569c9a43c.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (932adc9cdfd90db8e4fa113500988fbd) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{917bde56e227445fe41f78c7bc97aeb2}] and profile ResourceProfile{UNKNOWN} with allocation id c6779d6d8767a90fa2c3bf73999212fd from resource manager.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c6779d6d8767a90fa2c3bf73999212fd.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (eaf80ac88dacba005157f964cb61f047) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{b1c6b188cdd9292e481fc5ea2959725f}] and profile ResourceProfile{UNKNOWN} with allocation id 82189e9e9fd2444c05dfa136b7fa23de from resource manager.
2021-04-07 19:14:50,113 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 82189e9e9fd2444c05dfa136b7fa23de.
2021-04-07 19:14:50,118 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a3f9c2a6b546bdfaed3d035a8e8f0e56) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,123 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (cb9e9b59974fe11160f51c1a3342d74d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,125 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (70b2cc59da09922efe658b51d219519a) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,158 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (db65b2d84052222a8357780af5f5c90b) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (b77dc530216c8eb6addad3051f083efa) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id b77dc530216c8eb6addad3051f083efa to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,161 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (438ab3062f675a860a3f4dee2d1576b2) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d68d0f2f1c13f9c8934931c0a8034fdf) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id d68d0f2f1c13f9c8934931c0a8034fdf to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (5d7604bf660b1ac8c47a3b55d81730fd) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,163 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (4688694675f239e4f9fab0e028c1e0c4) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,163 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 4688694675f239e4f9fab0e028c1e0c4 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (d423c9bac961e4f1250093f4a903b8ba) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{e5a0573c8c35005837874ff3d7d8313e}] and profile ResourceProfile{UNKNOWN} with allocation id 8dfc40dd1bb5a24d30f96e29662e3b6b from resource manager.
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 8dfc40dd1bb5a24d30f96e29662e3b6b.
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (997d6d71dea2145c727aaf9101d38466) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{5ba4e5891bdbe6737590864fc7f4ebdc}] and profile ResourceProfile{UNKNOWN} with allocation id 4ac0ddb9b4f2e36b1de40e8ffdde8af7 from resource manager.
2021-04-07 19:14:50,164 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 4ac0ddb9b4f2e36b1de40e8ffdde8af7.
2021-04-07 19:14:50,165 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (d1fbc077095b76d29da55b386a977431) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,165 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{5e2e6e77505bb092cad1ba1636954773}] and profile ResourceProfile{UNKNOWN} with allocation id 08dd2dbdbe39a130c3ff10fe125efa5d from resource manager.
2021-04-07 19:14:50,165 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 08dd2dbdbe39a130c3ff10fe125efa5d.
2021-04-07 19:14:50,175 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (b77dc530216c8eb6addad3051f083efa) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d68d0f2f1c13f9c8934931c0a8034fdf) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,183 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (4688694675f239e4f9fab0e028c1e0c4) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,284 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a3f9c2a6b546bdfaed3d035a8e8f0e56) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,284 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a490714eead0e4b8ffa99c98c2b48677) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,284 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id a490714eead0e4b8ffa99c98c2b48677 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (70b2cc59da09922efe658b51d219519a) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e0d87c57c0ad667b43cbe79d04c8460e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id e0d87c57c0ad667b43cbe79d04c8460e to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (cb9e9b59974fe11160f51c1a3342d74d) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,288 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9e20ae2809e67cfc571ef30dd017acaf) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,288 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 9e20ae2809e67cfc571ef30dd017acaf to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,290 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (cee7051f283e5e31506a71952d3284a1) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,291 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{6f18b1d2464ee82329f302baa118732c}] and profile ResourceProfile{UNKNOWN} with allocation id e2a9caf8456e4bf649b6adc956cba4f7 from resource manager.
2021-04-07 19:14:50,291 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id e2a9caf8456e4bf649b6adc956cba4f7.
2021-04-07 19:14:50,291 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (732fded15092ab846cf3ab41bac02262) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,291 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1d4be531d23ec00b25eac2f4ae17c89a}] and profile ResourceProfile{UNKNOWN} with allocation id 60e4edc56f70d5c3e06c2eadc7b185dc from resource manager.
2021-04-07 19:14:50,292 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 60e4edc56f70d5c3e06c2eadc7b185dc.
2021-04-07 19:14:50,292 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (5bc7df0a398bff9303739ae1a0378c10) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,292 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{0976be470f29bf057332d9f277ca4374}] and profile ResourceProfile{UNKNOWN} with allocation id edef4fdff4162663fdcd86c17d682f5e from resource manager.
2021-04-07 19:14:50,292 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id edef4fdff4162663fdcd86c17d682f5e.
2021-04-07 19:14:50,298 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a490714eead0e4b8ffa99c98c2b48677) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,300 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e0d87c57c0ad667b43cbe79d04c8460e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,304 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9e20ae2809e67cfc571ef30dd017acaf) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d68d0f2f1c13f9c8934931c0a8034fdf) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (3003f59ed8849d9c3c5e1254a8066a68) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id 3003f59ed8849d9c3c5e1254a8066a68 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,358 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (b77dc530216c8eb6addad3051f083efa) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,358 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e3bded0698f8813f75f1df0dd8cf09b0) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,358 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id e3bded0698f8813f75f1df0dd8cf09b0 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,359 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (4688694675f239e4f9fab0e028c1e0c4) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,359 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (e8e0fbebc80df857700dcc1f12ca6fe1) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,359 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id e8e0fbebc80df857700dcc1f12ca6fe1 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,360 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (3a654aadc8266f2005a6f62216cc6e63) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,360 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{d6a82b6274d51b373c8accb8eb772c91}] and profile ResourceProfile{UNKNOWN} with allocation id a78d61ac0d5e14c75ca926991772a9c3 from resource manager.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id a78d61ac0d5e14c75ca926991772a9c3.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (91eda634e57a89309e9821950f8ed647) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1c4d664a61ee0315cd6973dfc075942a}] and profile ResourceProfile{UNKNOWN} with allocation id c8d03dbcc782e19e4b7d58b8d822d542 from resource manager.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c8d03dbcc782e19e4b7d58b8d822d542.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (681ea7414e3b5a1b3b687c3760330aa2) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{e3b94d3ca7bb4f7b2c7af9702f83774b}] and profile ResourceProfile{UNKNOWN} with allocation id 1c2e06acd9ae6f3208a0b2413d9beb42 from resource manager.
2021-04-07 19:14:50,361 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 1c2e06acd9ae6f3208a0b2413d9beb42.
2021-04-07 19:14:50,372 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (3003f59ed8849d9c3c5e1254a8066a68) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,377 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e3bded0698f8813f75f1df0dd8cf09b0) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,381 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (e8e0fbebc80df857700dcc1f12ca6fe1) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,428 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e0d87c57c0ad667b43cbe79d04c8460e) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (dc7e6f136dd35c124f011b28ed7605cd) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id dc7e6f136dd35c124f011b28ed7605cd to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9e20ae2809e67cfc571ef30dd017acaf) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d5eaff0899e9df32bdb85f08344b6914) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id d5eaff0899e9df32bdb85f08344b6914 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (a490714eead0e4b8ffa99c98c2b48677) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,433 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (f40a7ca01712e515fb1b77111e6e49ac) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,433 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id f40a7ca01712e515fb1b77111e6e49ac to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,434 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (254ae7bdca8f6f39a6cb857b9a4c493f) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,434 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{c2062e43bdf75b0637ae33162c08ac9a}] and profile ResourceProfile{UNKNOWN} with allocation id c3019b1cb62cb286872b63d4b96dface from resource manager.
2021-04-07 19:14:50,434 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c3019b1cb62cb286872b63d4b96dface.
2021-04-07 19:14:50,434 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (9be7b3d266f051252857348742f13aea) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,434 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{5a1b70bbea9cfab435a6a48aa35ef44d}] and profile ResourceProfile{UNKNOWN} with allocation id 29e5cc0a7e1a19ad04ff76cd859d7c5c from resource manager.
2021-04-07 19:14:50,435 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 29e5cc0a7e1a19ad04ff76cd859d7c5c.
2021-04-07 19:14:50,435 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (318742184b701797232c1bc922bce832) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,435 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{9024c921ec41d3bc7626b645c5b9c765}] and profile ResourceProfile{UNKNOWN} with allocation id 6ae88151dd0fe36c75b042a0043f58c0 from resource manager.
2021-04-07 19:14:50,435 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6ae88151dd0fe36c75b042a0043f58c0.
2021-04-07 19:14:50,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (dc7e6f136dd35c124f011b28ed7605cd) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d5eaff0899e9df32bdb85f08344b6914) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,444 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,444 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop1': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,445 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (f40a7ca01712e515fb1b77111e6e49ac) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,445 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 2 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,505 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (3003f59ed8849d9c3c5e1254a8066a68) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,506 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (200fd15c5e115272ff000bbc3252e7c0) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,506 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id 200fd15c5e115272ff000bbc3252e7c0 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,508 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (e3bded0698f8813f75f1df0dd8cf09b0) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,508 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (48df6e6e45d5b04de99199591aec46f7) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,508 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id 48df6e6e45d5b04de99199591aec46f7 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,509 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, subitemid, jcnuserid, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS subitemid CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (e8e0fbebc80df857700dcc1f12ca6fe1) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,509 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9ed7345283df21a584c9c51d03df3f65) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,509 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 9ed7345283df21a584c9c51d03df3f65 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,511 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (2f9d1d58f67195c03cbfb4cd7770ee20) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,511 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3218e31ee3438aafe86fec5fc805c230}] and profile ResourceProfile{UNKNOWN} with allocation id 45a67886666fa41357d7a68c7922ff6b from resource manager.
2021-04-07 19:14:50,511 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 45a67886666fa41357d7a68c7922ff6b.
2021-04-07 19:14:50,511 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f2df6474648791dde02d727092bd028b) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,512 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{7649add417d487d0b3ed29c6f150c5ff}] and profile ResourceProfile{UNKNOWN} with allocation id 844089f2fcea739906e1d386c29167e8 from resource manager.
2021-04-07 19:14:50,512 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 844089f2fcea739906e1d386c29167e8.
2021-04-07 19:14:50,512 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (96b0fa03365253cc1cf1ff9ea995a68c) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,512 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{c3a0b66856184cb118fd4ba748412e23}] and profile ResourceProfile{UNKNOWN} with allocation id 51079febaef780f7c2beb26a5a311a99 from resource manager.
2021-04-07 19:14:50,512 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 51079febaef780f7c2beb26a5a311a99.
2021-04-07 19:14:50,520 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (200fd15c5e115272ff000bbc3252e7c0) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,524 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (48df6e6e45d5b04de99199591aec46f7) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,528 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9ed7345283df21a584c9c51d03df3f65) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,560 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (f40a7ca01712e515fb1b77111e6e49ac) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,561 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (13019389ef531c8ecd98ddb0022eb368) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,561 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (attempt #0) with attempt id 13019389ef531c8ecd98ddb0022eb368 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (d5eaff0899e9df32bdb85f08344b6914) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (fdf8686770eae277fac69231213bc5b7) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (attempt #0) with attempt id fdf8686770eae277fac69231213bc5b7 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (dc7e6f136dd35c124f011b28ed7605cd) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (2f2d1e3ed33df21669e27982739c66d4) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (attempt #0) with attempt id 2f2d1e3ed33df21669e27982739c66d4 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,564 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (f1e77f6f2c5a76a99158035fbc93124e) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,564 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{7d5e3ccf6f3e970eb5a2a9165913b42e}] and profile ResourceProfile{UNKNOWN} with allocation id 0df4cc589d6106c7457a325ad0e49cae from resource manager.
2021-04-07 19:14:50,564 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 0df4cc589d6106c7457a325ad0e49cae.
2021-04-07 19:14:50,564 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (6b3f49cfb3030a3663a72f6b633e989f) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,565 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{7031eedbbc27cceed07642ff71c4df68}] and profile ResourceProfile{UNKNOWN} with allocation id 7ac72885451ddd1decbb0b7afb39db66 from resource manager.
2021-04-07 19:14:50,565 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 7ac72885451ddd1decbb0b7afb39db66.
2021-04-07 19:14:50,565 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (abd4cc9f62f035d32effe567a901d6c4) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,565 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{5690758a7cd46df963c3b05153b41b90}] and profile ResourceProfile{UNKNOWN} with allocation id db316b24709924a4ded1c1d08efe728a from resource manager.
2021-04-07 19:14:50,565 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id db316b24709924a4ded1c1d08efe728a.
2021-04-07 19:14:50,571 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (13019389ef531c8ecd98ddb0022eb368) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,573 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (fdf8686770eae277fac69231213bc5b7) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,576 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (2f2d1e3ed33df21669e27982739c66d4) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,644 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (48df6e6e45d5b04de99199591aec46f7) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (ce595a07c1e072c2f9e289443dd5b83f) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,645 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id ce595a07c1e072c2f9e289443dd5b83f to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,647 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (9ed7345283df21a584c9c51d03df3f65) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,647 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (932adc9cdfd90db8e4fa113500988fbd) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,647 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 932adc9cdfd90db8e4fa113500988fbd to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (200fd15c5e115272ff000bbc3252e7c0) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (eaf80ac88dacba005157f964cb61f047) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id eaf80ac88dacba005157f964cb61f047 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,651 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (c19eaff775c908ec14a4045f1b2327e9) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,651 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3881408694f4861437651267cf73d2d5}] and profile ResourceProfile{UNKNOWN} with allocation id c21d60a42f90c6fd9897f4775105ea27 from resource manager.
2021-04-07 19:14:50,651 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c21d60a42f90c6fd9897f4775105ea27.
2021-04-07 19:14:50,651 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (e04bf3e7ba3a41049d41075611d01584) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,652 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1e043c03629b5d43a2149dbc7bdb2714}] and profile ResourceProfile{UNKNOWN} with allocation id bbf3b1b64516c855772245038b64478c from resource manager.
2021-04-07 19:14:50,652 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id bbf3b1b64516c855772245038b64478c.
2021-04-07 19:14:50,652 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (c5dee65dad2cecf1e405e0ba5730142c) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,652 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3cdf5cb76da6e0c04eb382c8cc0b2653}] and profile ResourceProfile{UNKNOWN} with allocation id 464aa41c4240a645de7563391b908d83 from resource manager.
2021-04-07 19:14:50,652 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 464aa41c4240a645de7563391b908d83.
2021-04-07 19:14:50,659 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (ce595a07c1e072c2f9e289443dd5b83f) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,661 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (932adc9cdfd90db8e4fa113500988fbd) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,663 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (eaf80ac88dacba005157f964cb61f047) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,679 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (2/3) (fdf8686770eae277fac69231213bc5b7) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,680 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (d423c9bac961e4f1250093f4a903b8ba) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,680 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id d423c9bac961e4f1250093f4a903b8ba to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,693 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (d423c9bac961e4f1250093f4a903b8ba) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (3/3) (2f2d1e3ed33df21669e27982739c66d4) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (997d6d71dea2145c727aaf9101d38466) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,694 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 997d6d71dea2145c727aaf9101d38466 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(itemid = id)], select=[subtypeid, itemid, jcnuserid, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, subtypeid, jcnuserid]) -> Expand(projects=[group_key, subtypeid, jcnuserid, $e, jcnuserid_0], projects=[{group_key, subtypeid, jcnuserid, 0 AS $e, jcnuserid AS jcnuserid_0}, {group_key, subtypeid, null AS jcnuserid, 1 AS $e, jcnuserid AS jcnuserid_0}]) -> LocalHashAggregate(groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Partial_COUNT(jcnuserid_0) AS count$0]) (1/3) (13019389ef531c8ecd98ddb0022eb368) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (d1fbc077095b76d29da55b386a977431) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id d1fbc077095b76d29da55b386a977431 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (8705aa5351ba9816226c32dd76683b9a) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,702 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{01602e391e1181572fbc433e1c32967d}] and profile ResourceProfile{UNKNOWN} with allocation id 019ec1b4feeb3fefe94908ef5c5007d4 from resource manager.
2021-04-07 19:14:50,703 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 019ec1b4feeb3fefe94908ef5c5007d4.
2021-04-07 19:14:50,703 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f0880ead298b7be660206e1b0abbc377) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,703 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{bfa5cf7eea6883053ef8bf68e9b0b460}] and profile ResourceProfile{UNKNOWN} with allocation id 680491c5c9f1035635a9f23fbc347df7 from resource manager.
2021-04-07 19:14:50,703 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 680491c5c9f1035635a9f23fbc347df7.
2021-04-07 19:14:50,703 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (78447660b75ac0ad87992b9d358a6487) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,704 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{9e9c09b0e73ff9d1a9e287e1b40881e5}] and profile ResourceProfile{UNKNOWN} with allocation id 545ad08ab4835bfe933e1df54e1ca918 from resource manager.
2021-04-07 19:14:50,704 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 545ad08ab4835bfe933e1df54e1ca918.
2021-04-07 19:14:50,705 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (997d6d71dea2145c727aaf9101d38466) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,711 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (d1fbc077095b76d29da55b386a977431) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,785 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (932adc9cdfd90db8e4fa113500988fbd) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,785 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (cee7051f283e5e31506a71952d3284a1) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,785 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id cee7051f283e5e31506a71952d3284a1 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,787 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (eaf80ac88dacba005157f964cb61f047) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,788 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (732fded15092ab846cf3ab41bac02262) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,788 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 732fded15092ab846cf3ab41bac02262 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,789 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (ce595a07c1e072c2f9e289443dd5b83f) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,789 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (5bc7df0a398bff9303739ae1a0378c10) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,790 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 5bc7df0a398bff9303739ae1a0378c10 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,791 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (42dffdf62be6ffbb9d354fdc087973b2) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,791 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{31306d32e9f8efea100e3f77f8237f8f}] and profile ResourceProfile{UNKNOWN} with allocation id 76a8d0fdfa479ec48a4ce230c0c78951 from resource manager.
2021-04-07 19:14:50,791 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 76a8d0fdfa479ec48a4ce230c0c78951.
2021-04-07 19:14:50,792 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (d8ab55e4e2cfe41dc9aaaf56db90c13d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,792 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{ebb6a0f2a5c57102c0e9195931ebed36}] and profile ResourceProfile{UNKNOWN} with allocation id 4e44f4e726a2ef00eab6a15b3c687623 from resource manager.
2021-04-07 19:14:50,792 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 4e44f4e726a2ef00eab6a15b3c687623.
2021-04-07 19:14:50,792 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (8b2a5df642acdf60684230283183f69e) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,793 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{15294ff01ec976eabd21bf84c88bee04}] and profile ResourceProfile{UNKNOWN} with allocation id 2f5b67252087d8d99ffe2b50d4830636 from resource manager.
2021-04-07 19:14:50,793 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 2f5b67252087d8d99ffe2b50d4830636.
2021-04-07 19:14:50,794 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (d1fbc077095b76d29da55b386a977431) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,794 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (3a654aadc8266f2005a6f62216cc6e63) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,794 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 3a654aadc8266f2005a6f62216cc6e63 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,796 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (997d6d71dea2145c727aaf9101d38466) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,797 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (91eda634e57a89309e9821950f8ed647) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,797 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 91eda634e57a89309e9821950f8ed647 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,798 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (d423c9bac961e4f1250093f4a903b8ba) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,798 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (681ea7414e3b5a1b3b687c3760330aa2) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,798 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 681ea7414e3b5a1b3b687c3760330aa2 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,799 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (78f6f2ce6cf3566c29adeb82f60353a7) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,799 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{4c39610c55c6f36f3e942d7492e02bb0}] and profile ResourceProfile{UNKNOWN} with allocation id 29b5843b5e5b9ce8c7a816cad06b2a52 from resource manager.
2021-04-07 19:14:50,799 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 29b5843b5e5b9ce8c7a816cad06b2a52.
2021-04-07 19:14:50,799 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (081232af3acb2b01650a02faedbb2a46) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,800 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{312d6513342e7374d3ba4b072b29d4fa}] and profile ResourceProfile{UNKNOWN} with allocation id b8769d1dcc686911a1c29f0ca8d7179e from resource manager.
2021-04-07 19:14:50,800 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id b8769d1dcc686911a1c29f0ca8d7179e.
2021-04-07 19:14:50,800 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (eafbf389aa9c6ed9d79adab799cc8150) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,800 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{25af670c0df51751a1b953ad5e051368}] and profile ResourceProfile{UNKNOWN} with allocation id 0023003e470cfa9d1ca2d1d17c3ddd18 from resource manager.
2021-04-07 19:14:50,800 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 0023003e470cfa9d1ca2d1d17c3ddd18.
2021-04-07 19:14:50,801 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (cee7051f283e5e31506a71952d3284a1) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,804 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (732fded15092ab846cf3ab41bac02262) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,804 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,804 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop1': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,804 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (3a654aadc8266f2005a6f62216cc6e63) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,805 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 2 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,807 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (91eda634e57a89309e9821950f8ed647) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,808 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (5bc7df0a398bff9303739ae1a0378c10) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,810 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (681ea7414e3b5a1b3b687c3760330aa2) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,870 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,870 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop1': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,871 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 2 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,884 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (3a654aadc8266f2005a6f62216cc6e63) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,884 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (254ae7bdca8f6f39a6cb857b9a4c493f) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,885 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 254ae7bdca8f6f39a6cb857b9a4c493f to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,886 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (91eda634e57a89309e9821950f8ed647) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,887 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (9be7b3d266f051252857348742f13aea) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,887 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 9be7b3d266f051252857348742f13aea to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,888 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (681ea7414e3b5a1b3b687c3760330aa2) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,888 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (318742184b701797232c1bc922bce832) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,888 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 318742184b701797232c1bc922bce832 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,889 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (0847bb14f372a031ea99ecdfa852af5d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,890 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{6d0f8abec973dc6b1e6655d6885e5440}] and profile ResourceProfile{UNKNOWN} with allocation id fff274d347b1659cf50a19740186c054 from resource manager.
2021-04-07 19:14:50,890 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id fff274d347b1659cf50a19740186c054.
2021-04-07 19:14:50,890 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (ed3a6a52d9633b3b3d35575ddc7cf471) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,890 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{c876258727137415d24a569df5d200c5}] and profile ResourceProfile{UNKNOWN} with allocation id 9f6794699dbbfd7b37396f5fe012bd79 from resource manager.
2021-04-07 19:14:50,891 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 9f6794699dbbfd7b37396f5fe012bd79.
2021-04-07 19:14:50,891 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (33dfc6c14a7700f415de49e0af8f4175) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,891 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1d403d5a37e323a64608e5b223cf81b6}] and profile ResourceProfile{UNKNOWN} with allocation id 77a9aeafd4909ae13435c2b960aac679 from resource manager.
2021-04-07 19:14:50,891 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 77a9aeafd4909ae13435c2b960aac679.
2021-04-07 19:14:50,893 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (5bc7df0a398bff9303739ae1a0378c10) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,893 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (2f9d1d58f67195c03cbfb4cd7770ee20) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,893 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 2f9d1d58f67195c03cbfb4cd7770ee20 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,895 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (cee7051f283e5e31506a71952d3284a1) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,895 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f2df6474648791dde02d727092bd028b) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,895 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id f2df6474648791dde02d727092bd028b to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,896 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (732fded15092ab846cf3ab41bac02262) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,897 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (96b0fa03365253cc1cf1ff9ea995a68c) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,897 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 96b0fa03365253cc1cf1ff9ea995a68c to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,897 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (6d0862dfa4c2a77bb485b5d485c70be1) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,898 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{de8d9a15ccb069dbc6d22d85f141aa03}] and profile ResourceProfile{UNKNOWN} with allocation id db6f237c8a4fbacf1ceb5f4bd39a9d90 from resource manager.
2021-04-07 19:14:50,898 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id db6f237c8a4fbacf1ceb5f4bd39a9d90.
2021-04-07 19:14:50,898 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (f3b7b6223db8b8011a5eb72c9e045824) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,898 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{181fd50e3c08656fd6fbcbba0da3e4d2}] and profile ResourceProfile{UNKNOWN} with allocation id 16a25f2441d232f89b3460b3d8796700 from resource manager.
2021-04-07 19:14:50,899 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 16a25f2441d232f89b3460b3d8796700.
2021-04-07 19:14:50,899 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (e28adadfc90c98c5b6529cd8be97b397) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,899 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{c64e12d5fdfb38f8e2b9fdc8a08cc2b2}] and profile ResourceProfile{UNKNOWN} with allocation id 7a93e4f9aa81775d2b487dce13164e0c from resource manager.
2021-04-07 19:14:50,899 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 7a93e4f9aa81775d2b487dce13164e0c.
2021-04-07 19:14:50,899 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (254ae7bdca8f6f39a6cb857b9a4c493f) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,900 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (9be7b3d266f051252857348742f13aea) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,902 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (318742184b701797232c1bc922bce832) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,907 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (2f9d1d58f67195c03cbfb4cd7770ee20) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,911 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f2df6474648791dde02d727092bd028b) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,915 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (96b0fa03365253cc1cf1ff9ea995a68c) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,933 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,933 INFO  org.apache.flink.connector.file.src.assigners.LocalityAwareSplitAssigner [] - Assigning local split to requesting host 'sdl-hadoop1': HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,934 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Assigned split to subtask 2 : HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=, field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}
2021-04-07 19:14:50,963 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (254ae7bdca8f6f39a6cb857b9a4c493f) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (f1e77f6f2c5a76a99158035fbc93124e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id f1e77f6f2c5a76a99158035fbc93124e to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:50,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (318742184b701797232c1bc922bce832) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (6b3f49cfb3030a3663a72f6b633e989f) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 6b3f49cfb3030a3663a72f6b633e989f to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:50,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (9be7b3d266f051252857348742f13aea) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (abd4cc9f62f035d32effe567a901d6c4) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id abd4cc9f62f035d32effe567a901d6c4 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:50,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (fb0852c5ca7777865aaa9df32dd6934a) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,969 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{f741534b35c4e805b17cedf3f313c21f}] and profile ResourceProfile{UNKNOWN} with allocation id 4ac01425736bad2d2f0ab86049f0d932 from resource manager.
2021-04-07 19:14:50,969 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 4ac01425736bad2d2f0ab86049f0d932.
2021-04-07 19:14:50,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (a2ebd653924604735e33943496f05fa5) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,970 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{4b2983e4bce669765aec2c6d8a516f37}] and profile ResourceProfile{UNKNOWN} with allocation id 6b2f92a7418e06dccc43bd048cd1c9ac from resource manager.
2021-04-07 19:14:50,970 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6b2f92a7418e06dccc43bd048cd1c9ac.
2021-04-07 19:14:50,971 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (b8dc4581be564226429b8fe30d839cc9) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,971 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{3de3c040c5fceb1c9f1ca0c964ce36ba}] and profile ResourceProfile{UNKNOWN} with allocation id 22858aaa850725827f5dff5cd0c2a22a from resource manager.
2021-04-07 19:14:50,971 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 22858aaa850725827f5dff5cd0c2a22a.
2021-04-07 19:14:50,973 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 1 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,973 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 1
2021-04-07 19:14:50,975 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (f1e77f6f2c5a76a99158035fbc93124e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,977 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (6b3f49cfb3030a3663a72f6b633e989f) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,979 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (abd4cc9f62f035d32effe567a901d6c4) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:50,982 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 2 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:50,982 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 2
2021-04-07 19:14:50,991 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f2df6474648791dde02d727092bd028b) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,992 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (c19eaff775c908ec14a4045f1b2327e9) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,992 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id c19eaff775c908ec14a4045f1b2327e9 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:50,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (2f9d1d58f67195c03cbfb4cd7770ee20) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (e04bf3e7ba3a41049d41075611d01584) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,994 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id e04bf3e7ba3a41049d41075611d01584 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:50,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (96b0fa03365253cc1cf1ff9ea995a68c) switched from RUNNING to FINISHED.
2021-04-07 19:14:50,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (c5dee65dad2cecf1e405e0ba5730142c) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:50,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id c5dee65dad2cecf1e405e0ba5730142c to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:50,996 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (9b49ee30339bd9da5c872989e45eae72) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,996 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{12de6ce9d90482920cab7fa10f458847}] and profile ResourceProfile{UNKNOWN} with allocation id d927260ea2f67b76d1eade71810730c9 from resource manager.
2021-04-07 19:14:50,997 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id d927260ea2f67b76d1eade71810730c9.
2021-04-07 19:14:50,997 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (e6d8e28fc868b539504e73a6ef770e3d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,997 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{ce2818681beec75a91231086c6f023d5}] and profile ResourceProfile{UNKNOWN} with allocation id 6acbf4322b7cec2b0f565d6d4e1db857 from resource manager.
2021-04-07 19:14:50,997 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 6acbf4322b7cec2b0f565d6d4e1db857.
2021-04-07 19:14:50,997 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (d88cd060a6f28cf04bd2118edf9617b8) switched from CREATED to SCHEDULED.
2021-04-07 19:14:50,998 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{d1c24e8c6acd123be8b450307bd1ae71}] and profile ResourceProfile{UNKNOWN} with allocation id fa7725fec9de254be6f93c7a136794cb from resource manager.
2021-04-07 19:14:50,998 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id fa7725fec9de254be6f93c7a136794cb.
2021-04-07 19:14:51,005 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (c19eaff775c908ec14a4045f1b2327e9) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,007 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (e04bf3e7ba3a41049d41075611d01584) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,010 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (c5dee65dad2cecf1e405e0ba5730142c) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,060 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (6b3f49cfb3030a3663a72f6b633e989f) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,060 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (8705aa5351ba9816226c32dd76683b9a) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,060 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 8705aa5351ba9816226c32dd76683b9a to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:51,061 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (abd4cc9f62f035d32effe567a901d6c4) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f0880ead298b7be660206e1b0abbc377) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id f0880ead298b7be660206e1b0abbc377 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:51,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (f1e77f6f2c5a76a99158035fbc93124e) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (78447660b75ac0ad87992b9d358a6487) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 78447660b75ac0ad87992b9d358a6487 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:51,063 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (0409a34115e5951a882e53ec23bf2a3b) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,063 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{1ec9c9fa47815ddaee22badef38aea37}] and profile ResourceProfile{UNKNOWN} with allocation id c895cc39f1696d12396f7df7ed3576ff from resource manager.
2021-04-07 19:14:51,063 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id c895cc39f1696d12396f7df7ed3576ff.
2021-04-07 19:14:51,063 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (593c4be7bce1d61faa2ba9d405042be9) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,064 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{ed09aff7b338049762fdcb0fa0332d93}] and profile ResourceProfile{UNKNOWN} with allocation id 0206840b61d3e1ed73fba3e592c793b0 from resource manager.
2021-04-07 19:14:51,064 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 0206840b61d3e1ed73fba3e592c793b0.
2021-04-07 19:14:51,064 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (fa9b20141ae9219dffdb2c6842a0756e) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,064 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{035fc2766117d7ab4f2df866a5f8f5b8}] and profile ResourceProfile{UNKNOWN} with allocation id fb633dc7da4d6753c00d318a1da361b8 from resource manager.
2021-04-07 19:14:51,064 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id fb633dc7da4d6753c00d318a1da361b8.
2021-04-07 19:14:51,072 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (8705aa5351ba9816226c32dd76683b9a) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,073 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f0880ead298b7be660206e1b0abbc377) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,076 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (78447660b75ac0ad87992b9d358a6487) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,085 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (c19eaff775c908ec14a4045f1b2327e9) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,086 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (42dffdf62be6ffbb9d354fdc087973b2) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,086 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (attempt #0) with attempt id 42dffdf62be6ffbb9d354fdc087973b2 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:51,087 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (e04bf3e7ba3a41049d41075611d01584) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,087 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (d8ab55e4e2cfe41dc9aaaf56db90c13d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,087 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (attempt #0) with attempt id d8ab55e4e2cfe41dc9aaaf56db90c13d to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:51,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (c5dee65dad2cecf1e405e0ba5730142c) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (8b2a5df642acdf60684230283183f69e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (attempt #0) with attempt id 8b2a5df642acdf60684230283183f69e to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:51,088 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (b414eb79adb70ed01e9383aab96a98e0) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{9e33b45daadd4b7f3db142d79102b061}] and profile ResourceProfile{UNKNOWN} with allocation id 98460a085114bbe362fb3d6398adc38a from resource manager.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 98460a085114bbe362fb3d6398adc38a.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (57566fd18e511a08081dbbd197ac80fc) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{916c0c1d4ab8b54f1f6596170a7e18c7}] and profile ResourceProfile{UNKNOWN} with allocation id 70ae18e4dee674bf32ea1f51d901b7ef from resource manager.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 70ae18e4dee674bf32ea1f51d901b7ef.
2021-04-07 19:14:51,089 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (4a94172c86b6f4bef47703c5fd0032ce) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,090 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{eeff40721b06d600842d9143733dc3e3}] and profile ResourceProfile{UNKNOWN} with allocation id 816257911795da284de5870537c0ee00 from resource manager.
2021-04-07 19:14:51,090 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 816257911795da284de5870537c0ee00.
2021-04-07 19:14:51,098 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (42dffdf62be6ffbb9d354fdc087973b2) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,100 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (d8ab55e4e2cfe41dc9aaaf56db90c13d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,102 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (8b2a5df642acdf60684230283183f69e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,155 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (3/3) (78447660b75ac0ad87992b9d358a6487) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,156 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (78f6f2ce6cf3566c29adeb82f60353a7) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,156 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (attempt #0) with attempt id 78f6f2ce6cf3566c29adeb82f60353a7 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:51,158 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (2/3) (f0880ead298b7be660206e1b0abbc377) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,158 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (081232af3acb2b01650a02faedbb2a46) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,158 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (attempt #0) with attempt id 081232af3acb2b01650a02faedbb2a46 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:51,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid, jcnuserid, $e], select=[group_key, subtypeid, jcnuserid, $e, Final_COUNT(count$0) AS EXPR$0]) -> Calc(select=[group_key, subtypeid, jcnuserid, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(jcnuserid) FILTER $g_0 AS count$1]) (1/3) (8705aa5351ba9816226c32dd76683b9a) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (eafbf389aa9c6ed9d79adab799cc8150) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,159 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (attempt #0) with attempt id eafbf389aa9c6ed9d79adab799cc8150 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:51,160 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (2a0e5215f071c17ad3d796702e7ca4de) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,161 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{bcbffb7639962e3ebad67ece4af1b7e6}] and profile ResourceProfile{UNKNOWN} with allocation id 2573581b94ade15bdfb686a31a5cd863 from resource manager.
2021-04-07 19:14:51,161 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 2573581b94ade15bdfb686a31a5cd863.
2021-04-07 19:14:51,161 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (be8c38c3b99bdcc03e8edcabba682525) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,162 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{018fafeca262d7daa12c88b030312af6}] and profile ResourceProfile{UNKNOWN} with allocation id b90e6f841163bfabde275dbdbd541bca from resource manager.
2021-04-07 19:14:51,162 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id b90e6f841163bfabde275dbdbd541bca.
2021-04-07 19:14:51,162 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (43de90bdb9a603006099aa1b90b43067) switched from CREATED to SCHEDULED.
2021-04-07 19:14:51,162 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId{adfaeccc1a45e063ebdc74cba670c52a}] and profile ResourceProfile{UNKNOWN} with allocation id 7ef035ff29abd2e02a7d1075375974a9 from resource manager.
2021-04-07 19:14:51,162 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Request slot with profile ResourceProfile{UNKNOWN} for job ef1a60be8f725a192a72b12cbcc2769c with allocation id 7ef035ff29abd2e02a7d1075375974a9.
2021-04-07 19:14:51,163 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (d8ab55e4e2cfe41dc9aaaf56db90c13d) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (0847bb14f372a031ea99ecdfa852af5d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (attempt #0) with attempt id 0847bb14f372a031ea99ecdfa852af5d to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:51,165 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (42dffdf62be6ffbb9d354fdc087973b2) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (ed3a6a52d9633b3b3d35575ddc7cf471) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (attempt #0) with attempt id ed3a6a52d9633b3b3d35575ddc7cf471 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:51,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (8b2a5df642acdf60684230283183f69e) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (33dfc6c14a7700f415de49e0af8f4175) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (attempt #0) with attempt id 33dfc6c14a7700f415de49e0af8f4175 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:51,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (78f6f2ce6cf3566c29adeb82f60353a7) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,169 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (081232af3acb2b01650a02faedbb2a46) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (eafbf389aa9c6ed9d79adab799cc8150) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,178 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (0847bb14f372a031ea99ecdfa852af5d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (ed3a6a52d9633b3b3d35575ddc7cf471) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,183 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (33dfc6c14a7700f415de49e0af8f4175) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,216 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (78f6f2ce6cf3566c29adeb82f60353a7) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,217 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (6d0862dfa4c2a77bb485b5d485c70be1) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,217 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (attempt #0) with attempt id 6d0862dfa4c2a77bb485b5d485c70be1 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:51,218 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (eafbf389aa9c6ed9d79adab799cc8150) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,218 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (f3b7b6223db8b8011a5eb72c9e045824) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,218 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (attempt #0) with attempt id f3b7b6223db8b8011a5eb72c9e045824 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:51,226 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (6d0862dfa4c2a77bb485b5d485c70be1) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,227 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (081232af3acb2b01650a02faedbb2a46) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,227 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (e28adadfc90c98c5b6529cd8be97b397) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,227 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (attempt #0) with attempt id e28adadfc90c98c5b6529cd8be97b397 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:51,228 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (f3b7b6223db8b8011a5eb72c9e045824) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,229 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (33dfc6c14a7700f415de49e0af8f4175) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,230 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (fb0852c5ca7777865aaa9df32dd6934a) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,230 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (attempt #0) with attempt id fb0852c5ca7777865aaa9df32dd6934a to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:51,231 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (0847bb14f372a031ea99ecdfa852af5d) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,231 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (a2ebd653924604735e33943496f05fa5) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,231 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (attempt #0) with attempt id a2ebd653924604735e33943496f05fa5 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:51,236 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (e28adadfc90c98c5b6529cd8be97b397) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,243 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (fb0852c5ca7777865aaa9df32dd6934a) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,244 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (ed3a6a52d9633b3b3d35575ddc7cf471) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,245 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (b8dc4581be564226429b8fe30d839cc9) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,245 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (attempt #0) with attempt id b8dc4581be564226429b8fe30d839cc9 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:51,246 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (a2ebd653924604735e33943496f05fa5) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,257 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (b8dc4581be564226429b8fe30d839cc9) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,285 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (e28adadfc90c98c5b6529cd8be97b397) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (9b49ee30339bd9da5c872989e45eae72) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (attempt #0) with attempt id 9b49ee30339bd9da5c872989e45eae72 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:51,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (6d0862dfa4c2a77bb485b5d485c70be1) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (e6d8e28fc868b539504e73a6ef770e3d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (attempt #0) with attempt id e6d8e28fc868b539504e73a6ef770e3d to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:51,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (f3b7b6223db8b8011a5eb72c9e045824) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (d88cd060a6f28cf04bd2118edf9617b8) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (attempt #0) with attempt id d88cd060a6f28cf04bd2118edf9617b8 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:51,296 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (9b49ee30339bd9da5c872989e45eae72) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,296 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (e6d8e28fc868b539504e73a6ef770e3d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,302 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (d88cd060a6f28cf04bd2118edf9617b8) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,315 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (b8dc4581be564226429b8fe30d839cc9) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,316 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (0409a34115e5951a882e53ec23bf2a3b) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,316 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (attempt #0) with attempt id 0409a34115e5951a882e53ec23bf2a3b to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:51,317 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (a2ebd653924604735e33943496f05fa5) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,317 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (593c4be7bce1d61faa2ba9d405042be9) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,317 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (attempt #0) with attempt id 593c4be7bce1d61faa2ba9d405042be9 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:51,328 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (0409a34115e5951a882e53ec23bf2a3b) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,329 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (fb0852c5ca7777865aaa9df32dd6934a) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,329 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (fa9b20141ae9219dffdb2c6842a0756e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,329 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (attempt #0) with attempt id fa9b20141ae9219dffdb2c6842a0756e to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:51,330 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (593c4be7bce1d61faa2ba9d405042be9) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,341 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (fa9b20141ae9219dffdb2c6842a0756e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,354 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (d88cd060a6f28cf04bd2118edf9617b8) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (b414eb79adb70ed01e9383aab96a98e0) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,355 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (attempt #0) with attempt id b414eb79adb70ed01e9383aab96a98e0 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:51,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (9b49ee30339bd9da5c872989e45eae72) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (57566fd18e511a08081dbbd197ac80fc) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,356 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (attempt #0) with attempt id 57566fd18e511a08081dbbd197ac80fc to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:51,360 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (e6d8e28fc868b539504e73a6ef770e3d) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,360 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (4a94172c86b6f4bef47703c5fd0032ce) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,361 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (attempt #0) with attempt id 4a94172c86b6f4bef47703c5fd0032ce to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:51,366 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (b414eb79adb70ed01e9383aab96a98e0) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,367 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (57566fd18e511a08081dbbd197ac80fc) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,369 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (4a94172c86b6f4bef47703c5fd0032ce) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,387 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (1/3) (0409a34115e5951a882e53ec23bf2a3b) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,388 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (2a0e5215f071c17ad3d796702e7ca4de) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,388 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (attempt #0) with attempt id 2a0e5215f071c17ad3d796702e7ca4de to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:51,400 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (3/3) (fa9b20141ae9219dffdb2c6842a0756e) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,400 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (be8c38c3b99bdcc03e8edcabba682525) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,400 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (attempt #0) with attempt id be8c38c3b99bdcc03e8edcabba682525 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:51,401 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS click_group_key, CAST(EXPR$0) AS click_pv, EXPR$1 AS click_uv]) (2/3) (593c4be7bce1d61faa2ba9d405042be9) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,401 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (43de90bdb9a603006099aa1b90b43067) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:51,401 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (attempt #0) with attempt id 43de90bdb9a603006099aa1b90b43067 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:51,402 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (2a0e5215f071c17ad3d796702e7ca4de) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,414 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (3/3) (4a94172c86b6f4bef47703c5fd0032ce) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,415 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (be8c38c3b99bdcc03e8edcabba682525) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,416 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (43de90bdb9a603006099aa1b90b43067) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:51,420 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (1/3) (b414eb79adb70ed01e9383aab96a98e0) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,420 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS show_group_key, CAST(EXPR$0) AS show_pv, EXPR$1 AS show_uv]) (2/3) (57566fd18e511a08081dbbd197ac80fc) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,452 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (2/3) (be8c38c3b99bdcc03e8edcabba682525) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,458 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (3/3) (43de90bdb9a603006099aa1b90b43067) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,459 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[true], groupBy=[group_key, subtypeid], select=[group_key, subtypeid, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1]) -> Calc(select=[group_key AS save_group_key, CAST(EXPR$0) AS save_pv, EXPR$1 AS save_uv]) (1/3) (2a0e5215f071c17ad3d796702e7ca4de) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,794 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3) (b77b89626d62412743d18fac1233e404) switched from RUNNING to FINISHED.
2021-04-07 19:14:51,834 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - Subtask 0 (on host 'sdl-hadoop1.test.com') is requesting a file source split
2021-04-07 19:14:51,834 INFO  org.apache.flink.connector.file.src.impl.StaticFileSplitEnumerator [] - No more splits available for subtask 0
2021-04-07 19:14:51,845 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3) (07102f808e0eb210a1b2eabf7e2d1815) switched from RUNNING to FINISHED.
2021-04-07 19:14:52,164 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3) (30eebfce7ec8a3d33d9d262ec4ef8aa8) switched from RUNNING to FINISHED.
2021-04-07 19:14:52,165 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (121944f2dcbbfcc7427a2922acd6f52d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (121944f2dcbbfcc7427a2922acd6f52d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (attempt #0) with attempt id 121944f2dcbbfcc7427a2922acd6f52d to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id 3ccf514ce75c115dfb1451e7122e46f2
2021-04-07 19:14:52,166 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (f54d0a701c7f9bdbd85eaddd4b44bbc7) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (f54d0a701c7f9bdbd85eaddd4b44bbc7) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (attempt #0) with attempt id f54d0a701c7f9bdbd85eaddd4b44bbc7 to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id 32522b8210013182c4a072c2d3ffa963
2021-04-07 19:14:52,167 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b7a0fa2805c54bb120236f83dcebadec) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b7a0fa2805c54bb120236f83dcebadec) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (attempt #0) with attempt id b7a0fa2805c54bb120236f83dcebadec to container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034) with allocation id f59532e377b93e6c52dcbd0af2f1f976
2021-04-07 19:14:52,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (620e62691c59951e551a8ff5f4ef2dad) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (620e62691c59951e551a8ff5f4ef2dad) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,168 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (attempt #0) with attempt id 620e62691c59951e551a8ff5f4ef2dad to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:52,169 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (71be0ed10b54f0cdfd9008a52430335d) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,170 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (71be0ed10b54f0cdfd9008a52430335d) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,170 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (attempt #0) with attempt id 71be0ed10b54f0cdfd9008a52430335d to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:52,170 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (67fe373e5f83a83f5fba2c7bfe0d31ad) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (67fe373e5f83a83f5fba2c7bfe0d31ad) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (attempt #0) with attempt id 67fe373e5f83a83f5fba2c7bfe0d31ad to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:52,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (1de3bf4b6c7f7a86d74a8bf151d99382) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (1de3bf4b6c7f7a86d74a8bf151d99382) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,171 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (attempt #0) with attempt id 1de3bf4b6c7f7a86d74a8bf151d99382 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:52,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (86e1314b48ff1217b16e1565c6e4cb3f) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (86e1314b48ff1217b16e1565c6e4cb3f) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,172 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (attempt #0) with attempt id 86e1314b48ff1217b16e1565c6e4cb3f to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:52,173 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b06484638dac1c8167d07b2cfea34f4e) switched from CREATED to SCHEDULED.
2021-04-07 19:14:52,173 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b06484638dac1c8167d07b2cfea34f4e) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:52,173 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (attempt #0) with attempt id b06484638dac1c8167d07b2cfea34f4e to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:52,180 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (620e62691c59951e551a8ff5f4ef2dad) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,183 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (71be0ed10b54f0cdfd9008a52430335d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,184 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (67fe373e5f83a83f5fba2c7bfe0d31ad) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,187 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (1de3bf4b6c7f7a86d74a8bf151d99382) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,189 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (86e1314b48ff1217b16e1565c6e4cb3f) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,192 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b06484638dac1c8167d07b2cfea34f4e) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,222 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (f54d0a701c7f9bdbd85eaddd4b44bbc7) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,223 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (121944f2dcbbfcc7427a2922acd6f52d) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,223 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b7a0fa2805c54bb120236f83dcebadec) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:52,457 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (86e1314b48ff1217b16e1565c6e4cb3f) switched from RUNNING to FINISHED.
2021-04-07 19:14:52,458 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (620e62691c59951e551a8ff5f4ef2dad) switched from RUNNING to FINISHED.
2021-04-07 19:14:52,485 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (71be0ed10b54f0cdfd9008a52430335d) switched from RUNNING to FINISHED.
2021-04-07 19:14:52,854 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (1de3bf4b6c7f7a86d74a8bf151d99382) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,053 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b06484638dac1c8167d07b2cfea34f4e) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (0113ba8b4f3c271bc7ada754ba8505b1) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (0113ba8b4f3c271bc7ada754ba8505b1) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,055 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 0113ba8b4f3c271bc7ada754ba8505b1 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id b4063d98a5288887fa53a829571520d0
2021-04-07 19:14:53,056 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (42d3f09198f01086b9c822c2e002f321) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (42d3f09198f01086b9c822c2e002f321) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 42d3f09198f01086b9c822c2e002f321 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id 54d70d868a9bd9fcbf10eabad186615f
2021-04-07 19:14:53,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (014dc7ac5f718dda94578459402ee567) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,058 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (014dc7ac5f718dda94578459402ee567) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,058 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 014dc7ac5f718dda94578459402ee567 to container_e06_1616661788395_0878_01_000004 @ sdl-hadoop3.test.com (dataPort=18305) with allocation id e58eec0e6351ccfbcbc876480a843a87
2021-04-07 19:14:53,065 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (67fe373e5f83a83f5fba2c7bfe0d31ad) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,066 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (91f76e52595a10640ff8e476bc31e12b) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,066 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (91f76e52595a10640ff8e476bc31e12b) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,066 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (attempt #0) with attempt id 91f76e52595a10640ff8e476bc31e12b to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 5776a372bec5d4048805194bb91946e9
2021-04-07 19:14:53,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (1ab7b1af698be07cba8b28d372d86564) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (1ab7b1af698be07cba8b28d372d86564) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (attempt #0) with attempt id 1ab7b1af698be07cba8b28d372d86564 to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id 4c99269a322dd54af88720da987887a3
2021-04-07 19:14:53,067 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (2abaae0536dcbfcab69b0eb04c5c73bd) switched from CREATED to SCHEDULED.
2021-04-07 19:14:53,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (2abaae0536dcbfcab69b0eb04c5c73bd) switched from SCHEDULED to DEPLOYING.
2021-04-07 19:14:53,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (attempt #0) with attempt id 2abaae0536dcbfcab69b0eb04c5c73bd to container_e06_1616661788395_0878_01_000002 @ sdl-hadoop2.test.com (dataPort=6239) with allocation id e7e2794f16c496b733c0260bf0ab4914
2021-04-07 19:14:53,068 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (0113ba8b4f3c271bc7ada754ba8505b1) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,071 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (42d3f09198f01086b9c822c2e002f321) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,073 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (014dc7ac5f718dda94578459402ee567) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,077 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (91f76e52595a10640ff8e476bc31e12b) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,080 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (1ab7b1af698be07cba8b28d372d86564) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (2abaae0536dcbfcab69b0eb04c5c73bd) switched from DEPLOYING to RUNNING.
2021-04-07 19:14:53,134 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (0113ba8b4f3c271bc7ada754ba8505b1) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,135 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (014dc7ac5f718dda94578459402ee567) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,136 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (42d3f09198f01086b9c822c2e002f321) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,154 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (2abaae0536dcbfcab69b0eb04c5c73bd) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,154 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (1ab7b1af698be07cba8b28d372d86564) switched from RUNNING to FINISHED.
2021-04-07 19:14:53,155 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (91f76e52595a10640ff8e476bc31e12b) switched from RUNNING to FINISHED.
2021-04-07 19:14:55,344 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3) (b7a0fa2805c54bb120236f83dcebadec) switched from RUNNING to FAILED on container_e06_1616661788395_0878_01_000003 @ sdl-hadoop1.test.com (dataPort=1034).
java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
2021-04-07 19:14:55,376 INFO  org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy [] - Calculating tasks to restart to recover the failed task 46e2eda12ecb1f012ebf40d69e75175a_2.
2021-04-07 19:14:55,377 INFO  org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy [] - 1 tasks should be restarted to recover the failed task 46e2eda12ecb1f012ebf40d69e75175a_2. 
2021-04-07 19:14:55,380 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job collect (ef1a60be8f725a192a72b12cbcc2769c) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:118) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:80) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:233) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:224) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:215) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:669) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:447) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
Caused by: java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2021-04-07 19:14:55,387 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution df7e0e5506d50200874bb915f9ce739b.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 786e441f3cd9f31f21429044090af57e.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution a0d91bdfa1f72c7416ee9b92d09a6d3d.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ce36706c1bffcc41ba3e618665be5ca1.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 40320f90d98b6dfdfe04c2f25f6b9ffa.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d3800954e0430245c3a625e2bfbe892f.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 07102f808e0eb210a1b2eabf7e2d1815.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b77b89626d62412743d18fac1233e404.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 30eebfce7ec8a3d33d9d262ec4ef8aa8.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ca80c5654ea6bbd70d42ff14a4ddb814.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e7153f17913870a051f4b095071e1c1c.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 5bde70eebf4a96ba83f1dab66e3ce0e3.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 438ab3062f675a860a3f4dee2d1576b2.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution db65b2d84052222a8357780af5f5c90b.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 5d7604bf660b1ac8c47a3b55d81730fd.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d423c9bac961e4f1250093f4a903b8ba.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 997d6d71dea2145c727aaf9101d38466.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d1fbc077095b76d29da55b386a977431.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 78f6f2ce6cf3566c29adeb82f60353a7.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 081232af3acb2b01650a02faedbb2a46.
2021-04-07 19:14:55,390 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution eafbf389aa9c6ed9d79adab799cc8150.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 9a3d214ac7708aa56329f14b0d15b2e3.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b2b1c3de06970cb3bbc743dcf1ea9646.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution bfe9d6f5556b9f5deb6f7596e7671d85.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ce595a07c1e072c2f9e289443dd5b83f.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 932adc9cdfd90db8e4fa113500988fbd.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution eaf80ac88dacba005157f964cb61f047.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 42dffdf62be6ffbb9d354fdc087973b2.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d8ab55e4e2cfe41dc9aaaf56db90c13d.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 8b2a5df642acdf60684230283183f69e.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution a3f9c2a6b546bdfaed3d035a8e8f0e56.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution cb9e9b59974fe11160f51c1a3342d74d.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 70b2cc59da09922efe658b51d219519a.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution cee7051f283e5e31506a71952d3284a1.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 732fded15092ab846cf3ab41bac02262.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 5bc7df0a398bff9303739ae1a0378c10.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 6d0862dfa4c2a77bb485b5d485c70be1.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f3b7b6223db8b8011a5eb72c9e045824.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e28adadfc90c98c5b6529cd8be97b397.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b77dc530216c8eb6addad3051f083efa.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d68d0f2f1c13f9c8934931c0a8034fdf.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 4688694675f239e4f9fab0e028c1e0c4.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 3a654aadc8266f2005a6f62216cc6e63.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 91eda634e57a89309e9821950f8ed647.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 681ea7414e3b5a1b3b687c3760330aa2.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 0847bb14f372a031ea99ecdfa852af5d.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ed3a6a52d9633b3b3d35575ddc7cf471.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 33dfc6c14a7700f415de49e0af8f4175.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution a490714eead0e4b8ffa99c98c2b48677.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e0d87c57c0ad667b43cbe79d04c8460e.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 9e20ae2809e67cfc571ef30dd017acaf.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 254ae7bdca8f6f39a6cb857b9a4c493f.
2021-04-07 19:14:55,391 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 9be7b3d266f051252857348742f13aea.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 318742184b701797232c1bc922bce832.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution fb0852c5ca7777865aaa9df32dd6934a.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution a2ebd653924604735e33943496f05fa5.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b8dc4581be564226429b8fe30d839cc9.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 3003f59ed8849d9c3c5e1254a8066a68.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e3bded0698f8813f75f1df0dd8cf09b0.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e8e0fbebc80df857700dcc1f12ca6fe1.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 2f9d1d58f67195c03cbfb4cd7770ee20.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f2df6474648791dde02d727092bd028b.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 96b0fa03365253cc1cf1ff9ea995a68c.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 9b49ee30339bd9da5c872989e45eae72.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e6d8e28fc868b539504e73a6ef770e3d.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d88cd060a6f28cf04bd2118edf9617b8.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution dc7e6f136dd35c124f011b28ed7605cd.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution d5eaff0899e9df32bdb85f08344b6914.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f40a7ca01712e515fb1b77111e6e49ac.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f1e77f6f2c5a76a99158035fbc93124e.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 6b3f49cfb3030a3663a72f6b633e989f.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution abd4cc9f62f035d32effe567a901d6c4.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 0409a34115e5951a882e53ec23bf2a3b.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 593c4be7bce1d61faa2ba9d405042be9.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution fa9b20141ae9219dffdb2c6842a0756e.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 200fd15c5e115272ff000bbc3252e7c0.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 48df6e6e45d5b04de99199591aec46f7.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 9ed7345283df21a584c9c51d03df3f65.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c19eaff775c908ec14a4045f1b2327e9.
2021-04-07 19:14:55,392 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution e04bf3e7ba3a41049d41075611d01584.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c5dee65dad2cecf1e405e0ba5730142c.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b414eb79adb70ed01e9383aab96a98e0.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 57566fd18e511a08081dbbd197ac80fc.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 4a94172c86b6f4bef47703c5fd0032ce.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 13019389ef531c8ecd98ddb0022eb368.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution fdf8686770eae277fac69231213bc5b7.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 2f2d1e3ed33df21669e27982739c66d4.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 8705aa5351ba9816226c32dd76683b9a.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f0880ead298b7be660206e1b0abbc377.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 78447660b75ac0ad87992b9d358a6487.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 2a0e5215f071c17ad3d796702e7ca4de.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution be8c38c3b99bdcc03e8edcabba682525.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 43de90bdb9a603006099aa1b90b43067.
2021-04-07 19:14:55,393 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (121944f2dcbbfcc7427a2922acd6f52d) switched from RUNNING to CANCELING.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (f54d0a701c7f9bdbd85eaddd4b44bbc7) switched from RUNNING to CANCELING.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (56c582f753a4b5211c6bf4143aec0385) switched from CREATED to CANCELING.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3) (56c582f753a4b5211c6bf4143aec0385) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 56c582f753a4b5211c6bf4143aec0385.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (ad15f7e43743695cac751231aee5a8c5) switched from CREATED to CANCELING.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3) (ad15f7e43743695cac751231aee5a8c5) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution ad15f7e43743695cac751231aee5a8c5.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (304e3ea61faac81d1eeaad492831b17c) switched from CREATED to CANCELING.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3) (304e3ea61faac81d1eeaad492831b17c) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,396 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 304e3ea61faac81d1eeaad492831b17c.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 620e62691c59951e551a8ff5f4ef2dad.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 71be0ed10b54f0cdfd9008a52430335d.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 67fe373e5f83a83f5fba2c7bfe0d31ad.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 91f76e52595a10640ff8e476bc31e12b.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 1ab7b1af698be07cba8b28d372d86564.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 2abaae0536dcbfcab69b0eb04c5c73bd.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 1de3bf4b6c7f7a86d74a8bf151d99382.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 86e1314b48ff1217b16e1565c6e4cb3f.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution b06484638dac1c8167d07b2cfea34f4e.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 0113ba8b4f3c271bc7ada754ba8505b1.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 42d3f09198f01086b9c822c2e002f321.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 014dc7ac5f718dda94578459402ee567.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (1/3) (7290632fe6e74f21dd4c2e547ae2eee9) switched from CREATED to CANCELING.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (1/3) (7290632fe6e74f21dd4c2e547ae2eee9) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 7290632fe6e74f21dd4c2e547ae2eee9.
2021-04-07 19:14:55,397 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (2/3) (1fbffe9d33c277085d46fdf4bd348787) switched from CREATED to CANCELING.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (2/3) (1fbffe9d33c277085d46fdf4bd348787) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 1fbffe9d33c277085d46fdf4bd348787.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (3/3) (87095fde06bf59d3b869d16350b866a7) switched from CREATED to CANCELING.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - MultipleInput(readOrder=[0,0,0,0,0,0,1,0,1,0,1,0], members=[\nUnion(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:- Union(all=[true], union=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, purchase_pv, purchase_uv])\n:  :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:  :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:  :     :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:  :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:  :     :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:  :     :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:  :     :     :     :- [#9] Exchange(distribution=[hash[show_group_key]])\n:  :     :     :     +- [#10] Exchange(distribution=[hash[click_group_key]])\n:  :     :     +- [#3] Exchange(distribution=[hash[save_group_key]])\n:  :     +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:  :        +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:  :           +- [#4] Exchange(distribution=[hash[group_key]])\n:  +- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n:     +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n:        :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n:        :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n:        :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n:        :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n:        :     :     :- [#11] Exchange(distribution=[hash[show_group_key]])\n:        :     :     +- [#12] Exchange(distribution=[hash[click_group_key]])\n:        :     +- [#5] Exchange(distribution=[hash[save_group_key]])\n:        +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n:           +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n:              +- [#6] Exchange(distribution=[hash[group_key]])\n+- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, CASE(IS NULL(EXPR$0), 0:BIGINT, EXPR$0) AS purchase_pv, CASE(IS NULL(EXPR$1), 0:BIGINT, EXPR$1) AS purchase_uv])\n   +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_pv, save_uv, group_key, EXPR$0, EXPR$1], build=[right])\n      :- Calc(select=[show_group_key, show_pv, show_uv, click_pv, click_uv, CASE(IS NULL(save_pv), 0:BIGINT, save_pv) AS save_pv, CASE(IS NULL(save_uv), 0:BIGINT, save_uv) AS save_uv])\n      :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, save_group_key)], select=[show_group_key, show_pv, show_uv, click_pv, click_uv, save_group_key, save_pv, save_uv], build=[right])\n      :     :- Calc(select=[show_group_key, show_pv, show_uv, CASE(IS NULL(click_pv), 0:BIGINT, click_pv) AS click_pv, CASE(IS NULL(click_uv), 0:BIGINT, click_uv) AS click_uv])\n      :     :  +- HashJoin(joinType=[LeftOuterJoin], where=[=(show_group_key, click_group_key)], select=[show_group_key, show_pv, show_uv, click_group_key, click_pv, click_uv], build=[right])\n      :     :     :- [#7] Exchange(distribution=[hash[show_group_key]])\n      :     :     +- [#8] Exchange(distribution=[hash[click_group_key]])\n      :     +- [#1] Exchange(distribution=[hash[save_group_key]])\n      +- Calc(select=[group_key, CAST(EXPR$0) AS EXPR$0, EXPR$1])\n         +- HashAggregate(isMerge=[true], groupBy=[group_key], select=[group_key, Final_MIN(min$0) AS EXPR$0, Final_COUNT(count$1) AS EXPR$1])\n            +- [#2] Exchange(distribution=[hash[group_key]])\n]) (3/3) (87095fde06bf59d3b869d16350b866a7) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 87095fde06bf59d3b869d16350b866a7.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Sink: Select table sink (1/1) (73e3a9ce1dbeb791f51007cf14616a8e) switched from CREATED to CANCELING.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Sink: Select table sink (1/1) (73e3a9ce1dbeb791f51007cf14616a8e) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,398 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 73e3a9ce1dbeb791f51007cf14616a8e.
2021-04-07 19:14:55,579 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3) (f54d0a701c7f9bdbd85eaddd4b44bbc7) switched from CANCELING to CANCELED.
2021-04-07 19:14:55,579 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f54d0a701c7f9bdbd85eaddd4b44bbc7.
2021-04-07 19:14:55,580 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f54d0a701c7f9bdbd85eaddd4b44bbc7.
2021-04-07 19:14:56,596 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3) (121944f2dcbbfcc7427a2922acd6f52d) switched from CANCELING to CANCELED.
2021-04-07 19:14:56,596 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job collect (ef1a60be8f725a192a72b12cbcc2769c) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:118) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:80) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:233) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:224) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:215) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:669) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:89) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:447) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
Caused by: java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_181]
2021-04-07 19:14:56,604 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job ef1a60be8f725a192a72b12cbcc2769c.
2021-04-07 19:14:56,610 INFO  org.apache.flink.runtime.checkpoint.DefaultCompletedCheckpointStore [] - Shutting down
2021-04-07 19:14:56,610 INFO  org.apache.flink.runtime.zookeeper.ZooKeeperStateHandleStore [] - Removing /flink/application_1616661788395_0878/checkpoints/ef1a60be8f725a192a72b12cbcc2769c from ZooKeeper
2021-04-07 19:14:56,614 INFO  org.apache.flink.runtime.checkpoint.ZooKeeperCheckpointIDCounter [] - Shutting down.
2021-04-07 19:14:56,614 INFO  org.apache.flink.runtime.checkpoint.ZooKeeperCheckpointIDCounter [] - Removing /checkpoint-counter/ef1a60be8f725a192a72b12cbcc2769c from ZooKeeper
2021-04-07 19:14:56,624 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Job ef1a60be8f725a192a72b12cbcc2769c reached globally terminal state FAILED.
2021-04-07 19:14:56,626 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job collect(ef1a60be8f725a192a72b12cbcc2769c).
2021-04-07 19:14:56,626 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Stopping DefaultLeaderRetrievalService.
2021-04-07 19:14:56,626 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver [] - Closing ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/resource_manager_lock'}.
2021-04-07 19:14:56,631 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])).
2021-04-07 19:14:56,632 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) closed.
2021-04-07 19:14:56,636 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc).
2021-04-07 19:14:56,637 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) closed.
2021-04-07 19:14:56,640 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Suspending SlotPool.
2021-04-07 19:14:56,640 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 1dbe725c7841d065adc0770f97b5d926: Stopping JobMaster for job collect(ef1a60be8f725a192a72b12cbcc2769c)..
2021-04-07 19:14:56,641 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Stopping SlotPool.
2021-04-07 19:14:56,641 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Disconnect job manager ac16df4e2d7a122a3100c2b27753492d@akka.tcp://flink@sdl-hadoop2.test.com:13047/user/rpc/jobmanager_2 for job ef1a60be8f725a192a72b12cbcc2769c from the resource manager.
2021-04-07 19:14:56,657 INFO  org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService [] - Stopping DefaultLeaderElectionService.
2021-04-07 19:14:56,657 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver [] - Closing ZooKeeperLeaderElectionDriver{leaderPath='/leader/ef1a60be8f725a192a72b12cbcc2769c/job_manager_lock'}
2021-04-07 19:14:56,676 ERROR org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler [] - Unhandled exception.
org.apache.flink.runtime.messages.FlinkJobNotFoundException: Could not find Flink job (ef1a60be8f725a192a72b12cbcc2769c)
	at org.apache.flink.runtime.dispatcher.Dispatcher.getJobMasterGateway(Dispatcher.java:894) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.performOperationOnJobMasterGateway(Dispatcher.java:907) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.deliverCoordinationRequestToCoordinator(Dispatcher.java:731) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
2021-04-07 19:14:56,840 ERROR org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler [] - Unhandled exception.
org.apache.flink.runtime.messages.FlinkJobNotFoundException: Could not find Flink job (ef1a60be8f725a192a72b12cbcc2769c)
	at org.apache.flink.runtime.dispatcher.Dispatcher.getJobMasterGateway(Dispatcher.java:894) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.performOperationOnJobMasterGateway(Dispatcher.java:907) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.deliverCoordinationRequestToCoordinator(Dispatcher.java:731) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
2021-04-07 19:14:56,965 ERROR org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler [] - Unhandled exception.
org.apache.flink.runtime.messages.FlinkJobNotFoundException: Could not find Flink job (ef1a60be8f725a192a72b12cbcc2769c)
	at org.apache.flink.runtime.dispatcher.Dispatcher.getJobMasterGateway(Dispatcher.java:894) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.performOperationOnJobMasterGateway(Dispatcher.java:907) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.deliverCoordinationRequestToCoordinator(Dispatcher.java:731) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
2021-04-07 19:14:57,093 ERROR org.apache.flink.runtime.rest.handler.job.coordination.ClientCoordinationHandler [] - Unhandled exception.
org.apache.flink.runtime.messages.FlinkJobNotFoundException: Could not find Flink job (ef1a60be8f725a192a72b12cbcc2769c)
	at org.apache.flink.runtime.dispatcher.Dispatcher.getJobMasterGateway(Dispatcher.java:894) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.performOperationOnJobMasterGateway(Dispatcher.java:907) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.dispatcher.Dispatcher.deliverCoordinationRequestToCoordinator(Dispatcher.java:731) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_181]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_181]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:305) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:212) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:77) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:158) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:123) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:122) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive(Actor.scala:517) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.Actor.aroundReceive$(Actor.scala:515) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [flink-dist_2.12-1.12.2.jar:1.12.2]
2021-04-07 19:14:57,232 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Shutting down cluster because someone retrieved the job result.
2021-04-07 19:14:57,232 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Shutting YarnJobClusterEntrypoint down with application status FAILED. Diagnostics null.
2021-04-07 19:14:57,232 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Shutting down rest endpoint.
2021-04-07 19:14:57,272 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Removing cache directory /tmp/flink-web-df702f49-4742-42d1-aca5-f7f8ac5c13d6/flink-web-ui
2021-04-07 19:14:57,277 INFO  org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService [] - Stopping DefaultLeaderElectionService.
2021-04-07 19:14:57,277 INFO  org.apache.flink.runtime.leaderelection.ZooKeeperLeaderElectionDriver [] - Closing ZooKeeperLeaderElectionDriver{leaderPath='/leader/rest_server_lock'}
2021-04-07 19:14:57,278 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Shut down complete.
2021-04-07 19:14:57,278 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Shut down cluster because application is in FAILED, diagnostics null.
2021-04-07 19:14:57,280 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Unregister application from the YARN Resource Manager with final status FAILED.
2021-04-07 19:14:57,288 INFO  org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl        [] - Waiting for application to be successfully unregistered.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent [] - Closing components.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Stopping DefaultLeaderRetrievalService.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver [] - Closing ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/dispatcher_lock'}.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Stopping DefaultLeaderRetrievalService.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver [] - Closing ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/resource_manager_lock'}.
2021-04-07 19:14:57,394 INFO  org.apache.flink.runtime.leaderelection.DefaultLeaderElectionService [] - Stopping DefaultLeaderElectionService.