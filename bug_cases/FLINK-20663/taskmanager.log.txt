
LogType:taskmanager.log
LogLastModifiedTime:Wed Apr 07 19:01:31 +0800 2021
LogLength:289888
LogContents:
2021-04-07 19:00:59,110 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2021-04-07 19:00:59,114 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Starting YARN TaskExecutor runner (Version: 1.12.2, Scala: 2.12, Rev:4dedee0, Date:2021-02-26T17:14:28+01:00)
2021-04-07 19:00:59,114 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  OS current user: yarn
2021-04-07 19:00:59,352 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Current Hadoop/Kerberos user: root
2021-04-07 19:00:59,352 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.181-b13
2021-04-07 19:00:59,352 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Maximum heap size: 25064 MiBytes
2021-04-07 19:00:59,353 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JAVA_HOME: /usr/java/jdk1.8.0_181-cloudera
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Hadoop version: 3.1.1.7.1.1.0-565
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM Options:
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xmx27423827274
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xms27423827274
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxDirectMemorySize=1207959552
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxMetaspaceSize=268435456
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog.file=/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/taskmanager.log
2021-04-07 19:00:59,355 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configuration=file:./log4j.properties
2021-04-07 19:00:59,356 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configurationFile=file:./log4j.properties
2021-04-07 19:00:59,356 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Program Arguments:
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.off-heap.size=134217728b
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.max=1073741824b
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.min=1073741824b
2021-04-07 19:00:59,358 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.heap.size=134217728b
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.managed.size=19087858358b
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.cpu.cores=3.0
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.heap.size=27289609546b
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.off-heap.size=0b
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2021-04-07 19:00:59,359 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.max=1073741824b
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.min=1073741824b
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     --configDir
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     .
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.address=sdl-hadoop1.test.com
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.min=1073741824b
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dtaskmanager.resource-id=container_e06_1616661788395_0876_01_000003
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.port=0
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.off-heap.size=134217728b
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.tmpdir=/tmp/flink-web-59926193-f17f-44e0-96a4-e6115fda0544
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dinternal.taskmanager.resource-id.metadata=sdl-hadoop2.test.com:8041
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.port=22255
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Drest.address=sdl-hadoop1.test.com
2021-04-07 19:00:59,360 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-metaspace.size=268435456b
2021-04-07 19:00:59,361 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.heap.size=25887244288b
2021-04-07 19:00:59,361 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.max=1073741824b
2021-04-07 19:00:59,361 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Classpath: 
2021-04-07 19:00:59,363 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2021-04-07 19:00:59,364 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2021-04-07 19:00:59,366 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working Directory: /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003
2021-04-07 19:00:59,378 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.jobgraph-path, job.graph
2021-04-07 19:00:59,378 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.checkpoints.num-retained, 10
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1616661788395_0876
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.savepoints.dir, hdfs://jcn1/flink/1.12.2/savepoints/
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: python.client.executable, /space/conda/bin/python
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.path.root, /flink
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.storageDir, hdfs://jcn1/flink/1.12.2/recovery
2021-04-07 19:00:59,379 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 3
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application-attempts, 4
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 3
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.hadoop.conf.dir, /etc/hadoop/conf
2021-04-07 19:00:59,380 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file ./flink-conf.yaml:15: "pipeline.classpaths: "
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application.name, collocation
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 46789 mb
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: python.files, /space/airflow/dags/
2021-04-07 19:00:59,380 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-per-job
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 26096 mb
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.quorum, sdl-hadoop1:2181,sdl-hadoop2:2181,sdl-hadoop3:2181
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, true
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability, zookeeper
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/space/flink/opt/flink-python_2.12-1.12.2.jar
2021-04-07 19:00:59,381 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /space/flink/conf
2021-04-07 19:00:59,382 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /space/flink/conf/log4j.properties
2021-04-07 19:00:59,382 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.checkpoints.dir, hdfs://jcn1/flink/1.12.2/checkpoints/
2021-04-07 19:00:59,382 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working/local Directory: /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876
2021-04-07 19:00:59,393 INFO  org.apache.flink.runtime.clusterframework.BootstrapTools     [] - Setting directories for temporary files to: /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876
2021-04-07 19:00:59,394 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: local keytab path obtained null
2021-04-07 19:00:59,394 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: keytab principal obtained null
2021-04-07 19:00:59,399 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - YARN daemon is running as: root Yarn client user obtainer: root
2021-04-07 19:00:59,504 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user set to root (auth:SIMPLE)
2021-04-07 19:00:59,510 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/jaas-1506139487047921646.conf.
2021-04-07 19:01:00,061 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-04-07 19:01:00,078 INFO  org.apache.flink.runtime.blob.FileSystemBlobStore            [] - Creating highly available BLOB storage directory at hdfs://jcn1/flink/1.12.2/recovery/application_1616661788395_0876/blob
2021-04-07 19:01:00,143 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Enforcing default ACL for ZK connections
2021-04-07 19:01:00,144 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Using '/flink/application_1616661788395_0876' as Zookeeper namespace.
2021-04-07 19:01:00,180 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Running in ZooKeeper 3.4.x compatibility mode
2021-04-07 19:01:00,180 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Using emulated InjectSessionExpiration
2021-04-07 19:01:00,205 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Starting
2021-04-07 19:01:00,212 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
2021-04-07 19:01:00,213 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:host.name=sdl-hadoop2.test.com
2021-04-07 19:01:00,213 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.version=1.8.0_181
2021-04-07 19:01:00,213 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.vendor=Oracle Corporation
2021-04-07 19:01:00,213 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.home=/usr/java/jdk1.8.0_181-cloudera/jre
2021-04-07 19:01:00,213 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.class.path=:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-1.9.10-cdh6.3.2-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-scala_2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/aws-java-sdk-bundle-1.11.271.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-core-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/logredactor-2.0.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-api-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/wildfly-openssl-1.0.4.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-api-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/avro-1.8.2-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/zookeeper-3.4.5-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/objenesis-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/spark-2.4.0-cdh6.3.2-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/fst-2.50.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-4.0.jar
2021-04-07 19:01:00,214 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2021-04-07 19:01:00,214 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.io.tmpdir=/tmp
2021-04-07 19:01:00,214 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.compiler=<NA>
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.name=Linux
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.arch=amd64
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.version=3.10.0-957.el7.x86_64
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.name=yarn
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.home=/var/lib/hadoop-yarn
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.dir=/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003
2021-04-07 19:01:00,215 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Initiating client connection, connectString=sdl-hadoop1:2181,sdl-hadoop2:2181,sdl-hadoop3:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState@3359c978
2021-04-07 19:01:00,230 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Default schema
2021-04-07 19:01:00,232 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: sdl-hadoop2.test.com.
2021-04-07 19:01:00,235 WARN  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - SASL configuration failed: javax.security.auth.login.LoginException: No JAAS configuration section named 'Client' was found in specified JAAS configuration file: '/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/jaas-1506139487047921646.conf'. Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it.
2021-04-07 19:01:00,237 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Opening socket connection to server sdl-hadoop1/192.168.36.167:2181
2021-04-07 19:01:00,237 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address sdl-hadoop2.test.com:0, bind address 0.0.0.0:0.
2021-04-07 19:01:00,237 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Socket connection established to sdl-hadoop1/192.168.36.167:2181, initiating session
2021-04-07 19:01:00,238 ERROR org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState [] - Authentication failed
2021-04-07 19:01:00,244 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Session establishment complete on server sdl-hadoop1/192.168.36.167:2181, sessionid = 0x375e3324a524ce0, negotiated timeout = 40000
2021-04-07 19:01:00,246 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.state.ConnectionStateManager [] - State change: CONNECTED
2021-04-07 19:01:01,099 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-04-07 19:01:01,137 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-04-07 19:01:01,308 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@sdl-hadoop2.test.com:31500]
2021-04-07 19:01:01,616 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@sdl-hadoop2.test.com:31500
2021-04-07 19:01:01,641 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-07 19:01:01,644 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address sdl-hadoop2.test.com:0, bind address 0.0.0.0:0.
2021-04-07 19:01:01,661 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-04-07 19:01:01,667 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-04-07 19:01:01,687 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@sdl-hadoop2.test.com:3901]
2021-04-07 19:01:01,725 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@sdl-hadoop2.test.com:3901
2021-04-07 19:01:01,740 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_container_e06_1616661788395_0876_01_000003 .
2021-04-07 19:01:01,752 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/blobStore-2ed4f3d8-c490-4670-81b5-8518778903a7
2021-04-07 19:01:01,755 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/blobStore-f7cb1336-d13d-45e2-83ed-10e3ed2811c9
2021-04-07 19:01:01,758 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2021-04-07 19:01:01,759 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2021-04-07 19:01:01,759 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: container_e06_1616661788395_0876_01_000003(sdl-hadoop2.test.com:8041)
2021-04-07 19:01:01,786 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3668 GB, usable 3639 GB (99.21% usable)
2021-04-07 19:01:01,786 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3698 GB (99.33% usable)
2021-04-07 19:01:01,786 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3699 GB (99.36% usable)
2021-04-07 19:01:01,787 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3699 GB (99.36% usable)
2021-04-07 19:01:01,790 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-b0f0d270-7595-4a50-92f2-47b43fec90de for spill files.
2021-04-07 19:01:01,791 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-86c87a00-f97b-41c7-9b20-0c0eb16eaa7d for spill files.
2021-04-07 19:01:01,791 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-73003a53-d3fb-4a7f-9a6a-2c5442175c84 for spill files.
2021-04-07 19:01:01,791 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-1cead97b-618b-4fd3-abea-e9bb056704fb for spill files.
2021-04-07 19:01:01,800 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: /0.0.0.0, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 3 (manual), number of client threads: 3 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2021-04-07 19:01:01,802 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-0d175830-971b-44f9-ae84-78ecd7b0dc92 for spill files.
2021-04-07 19:01:01,803 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-eebe52eb-b09b-42c8-b3c9-075e26c7c231 for spill files.
2021-04-07 19:01:01,803 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-8ecd4524-5612-44bb-a5cc-23c37c5576bb for spill files.
2021-04-07 19:01:01,803 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-4e2d3b1f-890c-4a76-ae30-6e0c4cabebf2 for spill files.
2021-04-07 19:01:02,582 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 1024 MB for network buffer pool (number of memory segments: 32768, bytes per segment: 32768).
2021-04-07 19:01:02,594 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2021-04-07 19:01:02,655 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2021-04-07 19:01:02,656 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 62 ms).
2021-04-07 19:01:02,661 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2021-04-07 19:01:02,705 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 47 ms). Listening on SocketAddress /0.0.0.0:11436.
2021-04-07 19:01:02,706 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2021-04-07 19:01:02,734 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-07 19:01:02,778 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/resource_manager_lock'}.
2021-04-07 19:01:02,778 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2021-04-07 19:01:02,780 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-c2a2fa44-11ee-4584-be28-9bb2e9b348ea
2021-04-07 19:01:02,780 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-d877f18a-d417-4604-b345-eac92ea924bd
2021-04-07 19:01:02,780 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-dc9a7f69-b47d-416c-9d5e-d3566cecabec
2021-04-07 19:01:02,780 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-feb7419b-b212-480b-a351-466da5c93de6
2021-04-07 19:01:02,806 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/resourcemanager_0(a38ce14622d89070e0a262795a77418b).
2021-04-07 19:01:03,135 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2021-04-07 19:01:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/resourcemanager_0 under registration id 1c6a1f3067efe8453c9acc599d409cf3.
2021-04-07 19:01:03,264 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request efc817f4df67cc6581d230ec983ec855 for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,272 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for efc817f4df67cc6581d230ec983ec855.
2021-04-07 19:01:03,274 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job e6687ed64b39d3f73366d371bd24dd3a for job leader monitoring.
2021-04-07 19:01:03,276 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/e6687ed64b39d3f73366d371bd24dd3a/job_manager_lock'}.
2021-04-07 19:01:03,282 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/jobmanager_2 with leader id b4741056-b894-4a34-b270-f7625ffded0b.
2021-04-07 19:01:03,283 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 61a25424d50177c1394b4e53f7410f79 for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,284 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:03,286 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request f7f3b585004edfb5f6f7044fe516135e for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,286 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:03,303 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2021-04-07 19:01:03,324 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/jobmanager_2 for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,325 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,331 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,368 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:03,369 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:03,369 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot efc817f4df67cc6581d230ec983ec855.
2021-04-07 19:01:03,433 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot efc817f4df67cc6581d230ec983ec855.
2021-04-07 19:01:03,481 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299), deploy into slot with allocation id efc817f4df67cc6581d230ec983ec855.
2021-04-07 19:01:03,482 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,487 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) [DEPLOYING].
2021-04-07 19:01:03,490 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:03,495 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:03,496 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,497 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2) [DEPLOYING].
2021-04-07 19:01:03,497 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:03,501 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:03,502 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,502 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49) [DEPLOYING].
2021-04-07 19:01:03,508 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49) [DEPLOYING].
2021-04-07 19:01:03,508 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) [DEPLOYING].
2021-04-07 19:01:03,508 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2) [DEPLOYING].
2021-04-07 19:01:03,523 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,523 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,523 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,525 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,525 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,525 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,572 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,572 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,572 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,583 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:03,583 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:03,583 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:04,158 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,158 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,158 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,189 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,189 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,189 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,208 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,208 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,208 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,222 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,222 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,222 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,236 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,236 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,236 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,249 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,249 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,249 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,313 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,313 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,313 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:04,358 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-files/dags/dags
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-files/dags/dags
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-files/dags/dags
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives
2021-04-07 19:01:06,094 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives
2021-04-07 19:01:17,304 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:17,441 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:17,557 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:17,590 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:17,646 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:17,704 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:22,163 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:22,179 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 2-1
2021-04-07 19:01:22,180 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:22,181 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:22,182 WARN  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:22,183 WARN  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--app_name=BeamPythonFunctionRunner', '--options_id=1.0'] 
2021-04-07 19:01:22,184 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:22,185 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:22,186 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:31488.
2021-04-07 19:01:22,188 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:15107
2021-04-07 19:01:22,190 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:22,191 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:22,422 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=          , partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}]
2021-04-07 19:01:22,443 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2021-04-07 19:01:22,753 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 2-2
2021-04-07 19:01:22,753 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:22,764 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:22,765 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:22,766 WARN  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:22,767 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:726 [] - Creating insecure state channel for localhost:23116.
2021-04-07 19:01:22,767 WARN  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--app_name=BeamPythonFunctionRunner', '--options_id=2.0'] 
2021-04-07 19:01:22,768 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:733 [] - State channel established.
2021-04-07 19:01:22,768 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:22,770 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:22,770 INFO  /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/data_plane.py:636 [] - Creating client data channel for localhost:25815
2021-04-07 19:01:22,770 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 3-1
2021-04-07 19:01:22,771 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:6070.
2021-04-07 19:01:22,772 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:4455
2021-04-07 19:01:22,772 INFO  org.apache.beam.runners.fnexecution.data.GrpcDataService     [] - Beam Fn Data client connected.
2021-04-07 19:01:22,773 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:22,774 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:22,801 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=          , partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}]
2021-04-07 19:01:22,802 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2021-04-07 19:01:22,813 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/3:0+1557015]
2021-04-07 19:01:22,814 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/3:0+1557015]
2021-04-07 19:01:22,815 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 0 because it is idle.
2021-04-07 19:01:22,815 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2021-04-07 19:01:22,815 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2021-04-07 19:01:22,820 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=          , partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}]
2021-04-07 19:01:22,821 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 1
2021-04-07 19:01:22,860 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/1:1540454+178890]
2021-04-07 19:01:22,863 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/1:1540454+178890]
2021-04-07 19:01:22,864 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 1 because it is idle.
2021-04-07 19:01:22,864 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 1
2021-04-07 19:01:22,864 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 1 exited.
2021-04-07 19:01:22,866 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 3-2
2021-04-07 19:01:22,871 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:jcnuserid, type:string, comment:null), FieldSchema(name:action, type:string, comment:null), FieldSchema(name:typeid, type:string, comment:null), FieldSchema(name:subtypeid, type:string, comment:null), FieldSchema(name:itemid, type:string, comment:null), FieldSchema(name:subitemid, type:string, comment:null), FieldSchema(name:from_as, type:string, comment:null), FieldSchema(name:target, type:string, comment:null), FieldSchema(name:timestamp_as, type:bigint, comment:null), FieldSchema(name:ext, type:string, comment:null), FieldSchema(name:systemtype, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={name=chloe.chloe_common_stats_log, field.delim=	, columns.types=string:string:string:string:string:string:string:string:bigint:string:string, columns=jcnuserid,action,typeid,subtypeid,itemid,subitemid,from_as,target,timestamp_as,ext,systemtype, serialization.ddl=struct chloe_common_stats_log { string jcnuserid, string action, string typeid, string subtypeid, string itemid, string subitemid, string from_as, string target, i64 timestamp_as, string ext, string systemtype}, serialization.format=	, columns.comments=          , partition_columns.types=string, last_modified_time=1615863682, partition_columns=ds, bucket_count=-1, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, file.outputformat=org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log, last_modified_by=root, transient_lastDdlTime=1615863682}}}]
2021-04-07 19:01:22,871 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 2
2021-04-07 19:01:22,873 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:726 [] - Creating insecure state channel for localhost:16259.
2021-04-07 19:01:22,874 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:733 [] - State channel established.
2021-04-07 19:01:22,875 INFO  org.apache.beam.runners.fnexecution.environment.ProcessEnvironmentFactory [] - Still waiting for startup of environment '/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/pyflink/bin/pyflink-udf-runner.sh' for worker id 1-1
2021-04-07 19:01:22,875 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/data_plane.py:636 [] - Creating client data channel for localhost:13098
2021-04-07 19:01:22,879 INFO  org.apache.beam.runners.fnexecution.data.GrpcDataService     [] - Beam Fn Data client connected.
2021-04-07 19:01:22,918 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/1:0+1540454]
2021-04-07 19:01:22,921 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/1:0+1540454]
2021-04-07 19:01:22,921 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 0 because it is idle.
2021-04-07 19:01:22,921 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2021-04-07 19:01:22,921 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2021-04-07 19:01:22,929 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:22,952 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/2:0+1345003]
2021-04-07 19:01:22,956 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_common_stats_log/ds=2021-04-01/2:0+1345003]
2021-04-07 19:01:22,956 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 2 because it is idle.
2021-04-07 19:01:22,956 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 2
2021-04-07 19:01:22,956 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 2 exited.
2021-04-07 19:01:22,961 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:23,034 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:23,711 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:23,711 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:23,721 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:23,722 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:23,724 WARN  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:23,724 WARN  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--app_name=BeamPythonFunctionRunner', '--options_id=0.0'] 
2021-04-07 19:01:23,725 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:23,725 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:23,726 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:15638.
2021-04-07 19:01:23,726 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 1-1
2021-04-07 19:01:23,714 INFO  org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory [] - Closing environment urn: "beam:env:process:v1"
payload: "\032\324\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives/conda.zip/conda/lib/python3.7/site-packages/pyflink/bin/pyflink-udf-runner.sh\"K\n\017HADOOP_CONF_DIR\0228/var/run/cloudera-scm-agent/process/189-yarn-NODEMANAGER\",\n\tJAVA_HOME\022\037/usr/java/jdk1.8.0_181-cloudera\"$\n\023table.exec.timezone\022\rAsia/Shanghai\"!\n\aNM_HOST\022\026sdl-hadoop2.test.com\"\206\001\n\fBOOT_LOG_DIR\022v/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526\"\030\n\020HADOOP_USER_NAME\022\004root\")\n\033_PYTHON_WORKER_MEMORY_LIMIT\022\n6362619452\"Y\n\020HADOOP_HDFS_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs\"\017\n\aLOGNAME\022\004root\"\020\n\aJVM_PID\022\00514916\"`\n\022HADOOP_MAPRED_HOME\022J/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce\"w\n\003PWD\022p/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"(\n\016_FLINK_NODE_ID\022\026sdl-hadoop2.test.com\"V\n\022HADOOP_COMMON_HOME\022@/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop\"-\n\001_\022(/usr/java/jdk1.8.0_181-cloudera/bin/java\"\251\002\n\nLOCAL_DIRS\022\232\002/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876\"\234\001\n\nPYTHONPATH\022\215\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-files/dags/dags\"$\n\006python\022\032conda.zip/conda/bin/python\"\024\n\fNM_HTTP_PORT\022\0048042\"8\n\026HADOOP_CLIENT_CONF_DIR\022\036/etc/hadoop/conf.cloudera.yarn\" \n\030PYFLINK_GATEWAY_DISABLED\022\004true\"\243\003\n\bLOG_DIRS\022\226\003/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space1/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space2/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space3/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"\203\001\n\rPRELAUNCH_OUT\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.out\"P\n NM_AUX_SERVICE_mapreduce_shuffle\022,AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\017\n\aNM_PORT\022\0048041\"Y\n\020HADOOP_YARN_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn\"\f\n\004USER\022\004root\"\236\001\n\023_PYTHON_WORKING_DIR\022\206\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-3c841bb9-20e3-4381-abd3-f4f66da29526/python-archives\"\310\b\n\tCLASSPATH\022\272\b:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/*\"\203\001\n\rPRELAUNCH_ERR\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.err\"\240\001\n\032HADOOP_TOKEN_FILE_LOCATION\022\201\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/container_tokens\" \n\034NM_AUX_SERVICE_spark_shuffle\022\000\"\221\001\n\017LOCAL_USER_DIRS\022~/space/yarn/nm/usercache/root/,/space1/yarn/nm/usercache/root/,/space2/yarn/nm/usercache/root/,/space3/yarn/nm/usercache/root/\"\376\004\n\020_FLINK_CLASSPATH\022\351\004:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml:\"\n\n\005SHLVL\022\0012\"\016\n\004HOME\022\006/home/\":\n\fCONTAINER_ID\022*container_e06_1616661788395_0876_01_000003\"\025\n\020MALLOC_ARENA_MAX\022\0014"

2021-04-07 19:01:23,711 INFO  org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory [] - Closing environment urn: "beam:env:process:v1"
payload: "\032\325\001/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives/conda.zip/conda/lib/python3.7/site-packages/pyflink/bin/pyflink-udf-runner.sh\"K\n\017HADOOP_CONF_DIR\0228/var/run/cloudera-scm-agent/process/189-yarn-NODEMANAGER\",\n\tJAVA_HOME\022\037/usr/java/jdk1.8.0_181-cloudera\"$\n\023table.exec.timezone\022\rAsia/Shanghai\"!\n\aNM_HOST\022\026sdl-hadoop2.test.com\"\207\001\n\fBOOT_LOG_DIR\022w/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c\"\030\n\020HADOOP_USER_NAME\022\004root\")\n\033_PYTHON_WORKER_MEMORY_LIMIT\022\n6362619452\"Y\n\020HADOOP_HDFS_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs\"\017\n\aLOGNAME\022\004root\"\020\n\aJVM_PID\022\00514916\"`\n\022HADOOP_MAPRED_HOME\022J/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce\"w\n\003PWD\022p/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"(\n\016_FLINK_NODE_ID\022\026sdl-hadoop2.test.com\"V\n\022HADOOP_COMMON_HOME\022@/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop\"-\n\001_\022(/usr/java/jdk1.8.0_181-cloudera/bin/java\"\251\002\n\nLOCAL_DIRS\022\232\002/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876\"\235\001\n\nPYTHONPATH\022\216\001/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-files/dags/dags\"$\n\006python\022\032conda.zip/conda/bin/python\"\024\n\fNM_HTTP_PORT\022\0048042\"8\n\026HADOOP_CLIENT_CONF_DIR\022\036/etc/hadoop/conf.cloudera.yarn\" \n\030PYFLINK_GATEWAY_DISABLED\022\004true\"\243\003\n\bLOG_DIRS\022\226\003/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space1/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space2/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space3/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"\203\001\n\rPRELAUNCH_OUT\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.out\"P\n NM_AUX_SERVICE_mapreduce_shuffle\022,AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\017\n\aNM_PORT\022\0048041\"Y\n\020HADOOP_YARN_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn\"\f\n\004USER\022\004root\"\237\001\n\023_PYTHON_WORKING_DIR\022\207\001/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-f05978ed-59e9-4ad8-9d93-9471a86e9b8c/python-archives\"\310\b\n\tCLASSPATH\022\272\b:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/*\"\203\001\n\rPRELAUNCH_ERR\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.err\"\240\001\n\032HADOOP_TOKEN_FILE_LOCATION\022\201\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/container_tokens\" \n\034NM_AUX_SERVICE_spark_shuffle\022\000\"\221\001\n\017LOCAL_USER_DIRS\022~/space/yarn/nm/usercache/root/,/space1/yarn/nm/usercache/root/,/space2/yarn/nm/usercache/root/,/space3/yarn/nm/usercache/root/\"\376\004\n\020_FLINK_CLASSPATH\022\351\004:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml:\"\n\n\005SHLVL\022\0012\"\016\n\004HOME\022\006/home/\":\n\fCONTAINER_ID\022*container_e06_1616661788395_0876_01_000003\"\025\n\020MALLOC_ARENA_MAX\022\0014"

2021-04-07 19:01:23,727 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:17180
2021-04-07 19:01:23,728 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:23,728 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - 1 Beam Fn Logging clients still connected during shutdown.
2021-04-07 19:01:23,729 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - 1 Beam Fn Logging clients still connected during shutdown.
2021-04-07 19:01:23,730 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:23,739 WARN  org.apache.beam.sdk.fn.data.BeamFnDataGrpcMultiplexer        [] - Hanged up for unknown endpoint.
2021-04-07 19:01:23,761 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:23,761 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:23,764 INFO  org.apache.beam.runners.fnexecution.control.DefaultJobBundleFactory [] - Closing environment urn: "beam:env:process:v1"
payload: "\032\325\001/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives/conda.zip/conda/lib/python3.7/site-packages/pyflink/bin/pyflink-udf-runner.sh\"K\n\017HADOOP_CONF_DIR\0228/var/run/cloudera-scm-agent/process/189-yarn-NODEMANAGER\",\n\tJAVA_HOME\022\037/usr/java/jdk1.8.0_181-cloudera\"$\n\023table.exec.timezone\022\rAsia/Shanghai\"!\n\aNM_HOST\022\026sdl-hadoop2.test.com\"\207\001\n\fBOOT_LOG_DIR\022w/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3\"\030\n\020HADOOP_USER_NAME\022\004root\")\n\033_PYTHON_WORKER_MEMORY_LIMIT\022\n6362619452\"Y\n\020HADOOP_HDFS_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs\"\017\n\aLOGNAME\022\004root\"\020\n\aJVM_PID\022\00514916\"`\n\022HADOOP_MAPRED_HOME\022J/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-mapreduce\"w\n\003PWD\022p/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"(\n\016_FLINK_NODE_ID\022\026sdl-hadoop2.test.com\"V\n\022HADOOP_COMMON_HOME\022@/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop\"-\n\001_\022(/usr/java/jdk1.8.0_181-cloudera/bin/java\"\251\002\n\nLOCAL_DIRS\022\232\002/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876\"\235\001\n\nPYTHONPATH\022\216\001/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-files/dags/dags\"$\n\006python\022\032conda.zip/conda/bin/python\"\024\n\fNM_HTTP_PORT\022\0048042\"8\n\026HADOOP_CLIENT_CONF_DIR\022\036/etc/hadoop/conf.cloudera.yarn\" \n\030PYFLINK_GATEWAY_DISABLED\022\004true\"\243\003\n\bLOG_DIRS\022\226\003/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space1/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space2/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003,/space3/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003\"\203\001\n\rPRELAUNCH_OUT\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.out\"P\n NM_AUX_SERVICE_mapreduce_shuffle\022,AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\017\n\aNM_PORT\022\0048041\"Y\n\020HADOOP_YARN_HOME\022E/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn\"\f\n\004USER\022\004root\"\237\001\n\023_PYTHON_WORKING_DIR\022\207\001/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-8963cbe2-3420-4c3d-8307-2998ab9bbba3/python-archives\"\310\b\n\tCLASSPATH\022\272\b:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/*:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/*\"\203\001\n\rPRELAUNCH_ERR\022r/space/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/prelaunch.err\"\240\001\n\032HADOOP_TOKEN_FILE_LOCATION\022\201\001/space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000003/container_tokens\" \n\034NM_AUX_SERVICE_spark_shuffle\022\000\"\221\001\n\017LOCAL_USER_DIRS\022~/space/yarn/nm/usercache/root/,/space1/yarn/nm/usercache/root/,/space2/yarn/nm/usercache/root/,/space3/yarn/nm/usercache/root/\"\376\004\n\020_FLINK_CLASSPATH\022\351\004:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml:\"\n\n\005SHLVL\022\0012\"\016\n\004HOME\022\006/home/\":\n\fCONTAINER_ID\022*container_e06_1616661788395_0876_01_000003\"\025\n\020MALLOC_ARENA_MAX\022\0014"

2021-04-07 19:01:23,765 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - 1 Beam Fn Logging clients still connected during shutdown.
2021-04-07 19:01:24,576 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,576 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 (72e0d8babc330ce52732ea541f7786e2).
2021-04-07 19:01:24,579 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (1/3)#0 72e0d8babc330ce52732ea541f7786e2.
2021-04-07 19:01:24,606 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:24,626 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:24,627 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,627 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e) [DEPLOYING].
2021-04-07 19:01:24,632 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e) [DEPLOYING].
2021-04-07 19:01:24,633 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,633 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,640 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,640 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,667 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,681 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,744 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,785 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:24,808 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,808 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 (ca3745774934d9648899b7b9c167cd49).
2021-04-07 19:01:24,810 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (2/3)#0 ca3745774934d9648899b7b9c167cd49.
2021-04-07 19:01:24,822 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:24,824 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:24,825 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,825 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7) [DEPLOYING].
2021-04-07 19:01:24,827 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7) [DEPLOYING].
2021-04-07 19:01:24,827 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,827 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,828 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,828 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,832 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,833 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,834 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,839 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:24,941 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:24,981 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,088 INFO  LongHashJoinOperator$453                                     [] - Finish build phase.
2021-04-07 19:01:25,090 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:25,090 INFO  LongHashJoinOperator$453                                     [] - Finish build phase.
2021-04-07 19:01:25,091 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:25,197 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,201 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,222 INFO  LongHashJoinOperator$453                                     [] - Finish probe phase.
2021-04-07 19:01:25,222 INFO  LongHashJoinOperator$453                                     [] - Finish probe phase.
2021-04-07 19:01:25,222 INFO  LongHashJoinOperator$453                                     [] - Finish rebuild phase.
2021-04-07 19:01:25,222 INFO  LongHashJoinOperator$453                                     [] - Finish rebuild phase.
2021-04-07 19:01:25,226 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e) switched from RUNNING to FINISHED.
2021-04-07 19:01:25,226 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7) switched from RUNNING to FINISHED.
2021-04-07 19:01:25,226 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (36b8ee3b29d3e1aaac0d44a7bc48f0c7).
2021-04-07 19:01:25,226 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0162dd6a9832727bc9053c71ad7d090e).
2021-04-07 19:01:25,228 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 36b8ee3b29d3e1aaac0d44a7bc48f0c7.
2021-04-07 19:01:25,230 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 0162dd6a9832727bc9053c71ad7d090e.
2021-04-07 19:01:25,240 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:25,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:25,242 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616) switched from CREATED to DEPLOYING.
2021-04-07 19:01:25,243 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616) [DEPLOYING].
2021-04-07 19:01:25,243 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616) [DEPLOYING].
2021-04-07 19:01:25,243 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:25,243 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:25,244 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:25,245 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:25,245 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:25,245 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b) switched from CREATED to DEPLOYING.
2021-04-07 19:01:25,245 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:25,245 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b) [DEPLOYING].
2021-04-07 19:01:25,246 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b) [DEPLOYING].
2021-04-07 19:01:25,246 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:25,246 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:25,247 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:25,247 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:25,248 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,249 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,250 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,254 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:25,268 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,283 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,320 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,325 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:25,396 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,414 INFO  LongHashJoinOperator$453                                     [] - Finish build phase.
2021-04-07 19:01:25,415 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:25,445 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,449 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,459 INFO  LongHashJoinOperator$1318                                    [] - Finish build phase.
2021-04-07 19:01:25,459 INFO  LongHashJoinOperator$453                                     [] - Finish probe phase.
2021-04-07 19:01:25,459 INFO  LongHashJoinOperator$453                                     [] - Finish rebuild phase.
2021-04-07 19:01:25,460 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:25,464 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616) switched from RUNNING to FINISHED.
2021-04-07 19:01:25,464 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (d145d77bcfa2a3b1c08539160e52a616).
2021-04-07 19:01:25,466 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS _UTF-16LE'-1' CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 d145d77bcfa2a3b1c08539160e52a616.
2021-04-07 19:01:25,479 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:25,481 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:25,481 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5) switched from CREATED to DEPLOYING.
2021-04-07 19:01:25,481 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5) [DEPLOYING].
2021-04-07 19:01:25,482 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5) [DEPLOYING].
2021-04-07 19:01:25,482 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:25,483 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:25,483 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:25,483 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:25,485 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,486 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,486 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,489 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:25,501 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,522 INFO  LongHashJoinOperator$1318                                    [] - Finish probe phase.
2021-04-07 19:01:25,522 INFO  LongHashJoinOperator$1318                                    [] - Finish rebuild phase.
2021-04-07 19:01:25,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b) switched from RUNNING to FINISHED.
2021-04-07 19:01:25,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (52b501ca34b16c547830bae52336151b).
2021-04-07 19:01:25,525 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 52b501ca34b16c547830bae52336151b.
2021-04-07 19:01:25,534 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:25,538 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:25,540 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:25,540 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27) switched from CREATED to DEPLOYING.
2021-04-07 19:01:25,540 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27) [DEPLOYING].
2021-04-07 19:01:25,541 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27) [DEPLOYING].
2021-04-07 19:01:25,541 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:25,541 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:25,542 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:25,542 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:25,544 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,545 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,545 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:25,547 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:25,583 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,045 INFO  LongHashJoinOperator$1318                                    [] - Finish build phase.
2021-04-07 19:01:26,045 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:26,047 INFO  LongHashJoinOperator$1318                                    [] - Finish build phase.
2021-04-07 19:01:26,048 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - LongHybridHashTable: Use dense mode!
2021-04-07 19:01:26,096 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,102 INFO  LongHashJoinOperator$1318                                    [] - Finish probe phase.
2021-04-07 19:01:26,102 INFO  LongHashJoinOperator$1318                                    [] - Finish rebuild phase.
2021-04-07 19:01:26,105 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,110 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,110 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (f43af49aa5e899820aa157a0f1416fd5).
2021-04-07 19:01:26,110 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 f43af49aa5e899820aa157a0f1416fd5.
2021-04-07 19:01:26,113 INFO  LongHashJoinOperator$1318                                    [] - Finish probe phase.
2021-04-07 19:01:26,113 INFO  LongHashJoinOperator$1318                                    [] - Finish rebuild phase.
2021-04-07 19:01:26,115 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,115 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (515f530390be971676f9ac6eb0f79f27).
2021-04-07 19:01:26,115 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS _UTF-16LE'-1':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 515f530390be971676f9ac6eb0f79f27.
2021-04-07 19:01:26,127 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,129 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,129 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,129 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f) [DEPLOYING].
2021-04-07 19:01:26,130 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f) [DEPLOYING].
2021-04-07 19:01:26,130 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,130 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,130 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:26,132 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:26,132 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,132 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,132 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,132 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59) [DEPLOYING].
2021-04-07 19:01:26,133 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59) [DEPLOYING].
2021-04-07 19:01:26,133 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,133 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,134 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,134 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,168 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,168 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,182 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,182 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,220 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,220 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,229 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,231 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,235 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,236 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,236 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,237 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,253 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,253 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (b25ea0c4a7a3f43c45283f04a01ecf59).
2021-04-07 19:01:26,253 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,253 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (554c519d55e0a56c6112922d0b32590f).
2021-04-07 19:01:26,254 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 554c519d55e0a56c6112922d0b32590f.
2021-04-07 19:01:26,254 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 b25ea0c4a7a3f43c45283f04a01ecf59.
2021-04-07 19:01:26,265 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,266 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,267 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,267 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec) [DEPLOYING].
2021-04-07 19:01:26,267 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec) [DEPLOYING].
2021-04-07 19:01:26,268 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,268 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,268 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:26,269 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,269 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,270 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104), deploy into slot with allocation id f7f3b585004edfb5f6f7044fe516135e.
2021-04-07 19:01:26,270 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,270 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104) [DEPLOYING].
2021-04-07 19:01:26,271 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104) [DEPLOYING].
2021-04-07 19:01:26,271 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,271 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,272 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,272 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,274 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,275 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,275 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,280 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,282 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,283 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,287 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,287 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (6f6f510332fd982c5ebddeb5f5e244ec).
2021-04-07 19:01:26,287 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 6f6f510332fd982c5ebddeb5f5e244ec.
2021-04-07 19:01:26,300 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,301 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,303 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,303 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948) [DEPLOYING].
2021-04-07 19:01:26,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948) [DEPLOYING].
2021-04-07 19:01:26,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,305 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,305 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,308 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,313 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,313 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,349 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,349 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,352 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,352 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,355 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,356 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,357 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,357 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,367 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,367 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 (c601075eea877b00cf4674f1534f1948).
2021-04-07 19:01:26,367 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,367 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (2/3)#0 c601075eea877b00cf4674f1534f1948.
2021-04-07 19:01:26,367 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 (e61b5fc82422d62d39f55aa2b0d6a104).
2021-04-07 19:01:26,368 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (1/3)#0 e61b5fc82422d62d39f55aa2b0d6a104.
2021-04-07 19:01:26,379 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,381 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa), deploy into slot with allocation id 61a25424d50177c1394b4e53f7410f79.
2021-04-07 19:01:26,381 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa) switched from CREATED to DEPLOYING.
2021-04-07 19:01:26,381 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa) [DEPLOYING].
2021-04-07 19:01:26,381 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa) [DEPLOYING].
2021-04-07 19:01:26,382 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:26,382 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:26,382 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:26,383 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:26,385 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,386 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,386 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:26,389 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,390 INFO  org.apache.flink.table.runtime.operators.aggregate.BytesHashMap [] - BytesHashMap with initial memory segments 97085, -1113686016 in bytes, init allocating 32 for bucket area.
2021-04-07 19:01:26,391 INFO  org.apache.flink.runtime.io.network.partition.consumer.SingleInputGate [] - Converting recovered input channels (3 channels)
2021-04-07 19:01:26,394 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa) switched from RUNNING to FINISHED.
2021-04-07 19:01:26,394 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 (1d9c839f9b77c88e8686ac42932adffa).
2021-04-07 19:01:26,394 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task HashAggregate(isMerge=[false], groupBy=[group_key, user_id, $e], select=[group_key, user_id, $e, COUNT(user_id_0) AS EXPR$0]) -> Calc(select=[group_key, user_id, EXPR$0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 0) AS $g_0, ((($e = 0:BIGINT) CASE 0:BIGINT CASE 1:BIGINT) = 1) AS $g_1]) -> LocalHashAggregate(groupBy=[group_key], select=[group_key, Partial_MIN(EXPR$0) FILTER $g_1 AS min$0, Partial_COUNT(user_id) FILTER $g_0 AS count$1]) (3/3)#0 1d9c839f9b77c88e8686ac42932adffa.
2021-04-07 19:01:27,154 WARN  org.apache.beam.sdk.fn.data.BeamFnDataGrpcMultiplexer        [] - Hanged up for unknown endpoint.
2021-04-07 19:01:27,198 WARN  org.apache.beam.sdk.fn.data.BeamFnDataGrpcMultiplexer        [] - Hanged up for unknown endpoint.
2021-04-07 19:01:27,553 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299).
2021-04-07 19:01:27,553 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) switched from RUNNING to CANCELING.
2021-04-07 19:01:27,554 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299).
2021-04-07 19:01:28,082 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299) switched from CANCELING to CANCELED.
2021-04-07 19:01:28,082 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 (4a288d1ca86eec9fe0d3a36e5a325299).
2021-04-07 19:01:28,085 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: HiveSource-chloe.chloe_common_stats_log -> Calc(select=[CAST(_UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS typeid, subtypeid, itemid, subitemid, jcnuserid], where=[((typeid = _UTF-16LE'collocation':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AND (itemid <> _UTF-16LE'':VARCHAR(2147483647) CHARACTER SET "UTF-16LE"))]) -> BatchExecPythonCorrelate -> (Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, c AS subitemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')]), Calc(select=[CAST(_UTF-16LE'materialClick':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialClick')]), Calc(select=[CAST(_UTF-16LE'materialShow':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialShow')]), Calc(select=[CAST(_UTF-16LE'materialSave':VARCHAR(2147483647) CHARACTER SET "UTF-16LE") AS subtypeid, CAST(b) AS itemid, d AS jcnuserid], where=[(a = _UTF-16LE'materialSave')])) (3/3)#0 4a288d1ca86eec9fe0d3a36e5a325299.
2021-04-07 19:01:28,802 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:2, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: f7f3b585004edfb5f6f7044fe516135e, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:28,809 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: efc817f4df67cc6581d230ec983ec855, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:28,811 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: 61a25424d50177c1394b4e53f7410f79, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:28,811 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job e6687ed64b39d3f73366d371bd24dd3a from job leader monitoring.
2021-04-07 19:01:28,812 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Stopping DefaultLeaderRetrievalService.
2021-04-07 19:01:28,812 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver [] - Closing ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/e6687ed64b39d3f73366d371bd24dd3a/job_manager_lock'}.
2021-04-07 19:01:28,813 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:30,520 WARN  org.apache.flink.shaded.curator4.org.apache.curator.utils.ZKPaths [] - The version of ZooKeeper being used doesn't support Container nodes. CreateMode.PERSISTENT will be used instead.
2021-04-07 19:01:30,524 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection d39dd16b04f7cfeb68b2bc47f8845e3d.
2021-04-07 19:01:30,525 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2021-04-07 19:01:30,526 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2021-04-07 19:01:30,526 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-07 19:01:30,526 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2021-04-07 19:01:30,529 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-0d175830-971b-44f9-ae84-78ecd7b0dc92
2021-04-07 19:01:30,529 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-b0f0d270-7595-4a50-92f2-47b43fec90de
2021-04-07 19:01:30,529 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-eebe52eb-b09b-42c8-b3c9-075e26c7c231
2021-04-07 19:01:30,529 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-86c87a00-f97b-41c7-9b20-0c0eb16eaa7d
2021-04-07 19:01:30,530 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-8ecd4524-5612-44bb-a5cc-23c37c5576bb
2021-04-07 19:01:30,530 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-73003a53-d3fb-4a7f-9a6a-2c5442175c84
2021-04-07 19:01:30,530 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-4e2d3b1f-890c-4a76-ae30-6e0c4cabebf2
2021-04-07 19:01:30,530 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-1cead97b-618b-4fd3-abea-e9bb056704fb
2021-04-07 19:01:30,579 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [sdl-hadoop1.test.com/192.168.36.167:22255] failed with java.io.IOException: Connection reset by peer
2021-04-07 19:01:30,579 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/192.168.36.167:42487] failed with java.io.IOException: Connection reset by peer

End of LogType:taskmanager.log
********************************************************************************


End of LogType:taskmanager.out
********************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e06_1616661788395_0876_01_000004 on sdl-hadoop3.test.com_8041
LogAggregationType: AGGREGATED
====================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed Apr 07 19:01:31 +0800 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e06_1616661788395_0876_01_000004 on sdl-hadoop3.test.com_8041
LogAggregationType: AGGREGATED
====================================================================================
LogType:taskmanager.err
LogLastModifiedTime:Wed Apr 07 19:01:31 +0800 2021
LogLength:560
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/filecache/13/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

End of LogType:taskmanager.err
********************************************************************************

Container: container_e06_1616661788395_0876_01_000004 on sdl-hadoop3.test.com_8041
LogAggregationType: AGGREGATED
====================================================================================
LogType:taskmanager.log
LogLastModifiedTime:Wed Apr 07 19:01:31 +0800 2021
LogLength:186345
LogContents:
2021-04-07 19:00:59,222 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2021-04-07 19:00:59,226 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Starting YARN TaskExecutor runner (Version: 1.12.2, Scala: 2.12, Rev:4dedee0, Date:2021-02-26T17:14:28+01:00)
2021-04-07 19:00:59,226 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  OS current user: yarn
2021-04-07 19:00:59,443 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Current Hadoop/Kerberos user: root
2021-04-07 19:00:59,444 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.181-b13
2021-04-07 19:00:59,444 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Maximum heap size: 25064 MiBytes
2021-04-07 19:00:59,444 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JAVA_HOME: /usr/java/jdk1.8.0_181-cloudera
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Hadoop version: 3.1.1.7.1.1.0-565
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM Options:
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xmx27423827274
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xms27423827274
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxDirectMemorySize=1207959552
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxMetaspaceSize=268435456
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog.file=/space3/yarn/container-logs/application_1616661788395_0876/container_e06_1616661788395_0876_01_000004/taskmanager.log
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configuration=file:./log4j.properties
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configurationFile=file:./log4j.properties
2021-04-07 19:00:59,447 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Program Arguments:
2021-04-07 19:00:59,449 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,449 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.off-heap.size=134217728b
2021-04-07 19:00:59,449 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.max=1073741824b
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.min=1073741824b
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.heap.size=134217728b
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.managed.size=19087858358b
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.cpu.cores=3.0
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,450 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.heap.size=27289609546b
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.off-heap.size=0b
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.max=1073741824b
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.min=1073741824b
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     --configDir
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     .
2021-04-07 19:00:59,451 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.address=sdl-hadoop1.test.com
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.min=1073741824b
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dtaskmanager.resource-id=container_e06_1616661788395_0876_01_000004
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.port=0
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.off-heap.size=134217728b
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.tmpdir=/tmp/flink-web-59926193-f17f-44e0-96a4-e6115fda0544
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dinternal.taskmanager.resource-id.metadata=sdl-hadoop3.test.com:8041
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.port=22255
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Drest.address=sdl-hadoop1.test.com
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-metaspace.size=268435456b
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.heap.size=25887244288b
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.max=1073741824b
2021-04-07 19:00:59,452 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Classpath: :flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-1.9.10-cdh6.3.2-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-scala_2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/aws-java-sdk-bundle-1.11.271.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-core-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/logredactor-2.0.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-api-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/wildfly-openssl-1.0.4.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-api-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/avro-1.8.2-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/zookeeper-3.4.5-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/objenesis-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/spark-2.4.0-cdh6.3.2-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/fst-2.50.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-4.0.jar
2021-04-07 19:00:59,455 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2021-04-07 19:00:59,456 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2021-04-07 19:00:59,459 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working Directory: /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000004
2021-04-07 19:00:59,475 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.jobgraph-path, job.graph
2021-04-07 19:00:59,475 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.checkpoints.num-retained, 10
2021-04-07 19:00:59,475 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2021-04-07 19:00:59,475 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1616661788395_0876
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.savepoints.dir, hdfs://jcn1/flink/1.12.2/savepoints/
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: python.client.executable, /space/conda/bin/python
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.path.root, /flink
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.storageDir, hdfs://jcn1/flink/1.12.2/recovery
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2021-04-07 19:00:59,476 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 3
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application-attempts, 4
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 3
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: env.hadoop.conf.dir, /etc/hadoop/conf
2021-04-07 19:00:59,477 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file ./flink-conf.yaml:15: "pipeline.classpaths: "
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application.name, collocation
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 46789 mb
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: python.files, /space/airflow/dags/
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-per-job
2021-04-07 19:00:59,477 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 26096 mb
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.zookeeper.quorum, sdl-hadoop1:2181,sdl-hadoop2:2181,sdl-hadoop3:2181
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, true
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, NORMAL
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability, zookeeper
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/space/flink/opt/flink-python_2.12-1.12.2.jar
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /space/flink/conf
2021-04-07 19:00:59,478 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /space/flink/conf/log4j.properties
2021-04-07 19:00:59,479 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: state.checkpoints.dir, hdfs://jcn1/flink/1.12.2/checkpoints/
2021-04-07 19:00:59,479 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working/local Directory: /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876
2021-04-07 19:00:59,494 INFO  org.apache.flink.runtime.clusterframework.BootstrapTools     [] - Setting directories for temporary files to: /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876,/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876
2021-04-07 19:00:59,495 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: local keytab path obtained null
2021-04-07 19:00:59,495 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: keytab principal obtained null
2021-04-07 19:00:59,502 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - YARN daemon is running as: root Yarn client user obtainer: root
2021-04-07 19:00:59,636 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user set to root (auth:SIMPLE)
2021-04-07 19:00:59,643 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/jaas-6049651361304051356.conf.
2021-04-07 19:01:00,213 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-04-07 19:01:00,229 INFO  org.apache.flink.runtime.blob.FileSystemBlobStore            [] - Creating highly available BLOB storage directory at hdfs://jcn1/flink/1.12.2/recovery/application_1616661788395_0876/blob
2021-04-07 19:01:00,292 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Enforcing default ACL for ZK connections
2021-04-07 19:01:00,292 INFO  org.apache.flink.runtime.util.ZooKeeperUtils                 [] - Using '/flink/application_1616661788395_0876' as Zookeeper namespace.
2021-04-07 19:01:00,330 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Running in ZooKeeper 3.4.x compatibility mode
2021-04-07 19:01:00,331 INFO  org.apache.flink.shaded.curator4.org.apache.curator.utils.Compatibility [] - Using emulated InjectSessionExpiration
2021-04-07 19:01:00,357 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Starting
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:host.name=sdl-hadoop3.test.com
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.version=1.8.0_181
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.vendor=Oracle Corporation
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.home=/usr/java/jdk1.8.0_181-cloudera/jre
2021-04-07 19:01:00,365 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.class.path=:flink-python_2.12-1.12.2.jar:lib/flink-connector-jdbc_2.12-1.12.2.jar:lib/flink-csv-1.12.2.jar:lib/flink-json-1.12.2.jar:lib/flink-shaded-hadoop-3-uber-3.1.1.7.1.1.0-565-9.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-sql-connector-hive-2.2.0_2.12-1.12.2.jar:lib/flink-sql-connector-kafka_2.12-1.12.2.jar:lib/flink-table-blink_2.12-1.12.2.jar:lib/flink-table_2.12-1.12.2.jar:lib/hive-exec-2.1.1-cdh6.3.2.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-5.1.9.jar:flink-dist_2.12-1.12.2.jar:job.graph:flink-conf.yaml::/etc/hadoop/conf.cloudera.yarn:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-aws-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-annotations-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-auth-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/gcs-connector-hadoop3-1.9.10-cdh6.3.2-shaded.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-datalake-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-common-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-kms-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/hadoop-azure-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-scala_2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/aws-java-sdk-bundle-1.11.271.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-core-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jul-to-slf4j-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/logredactor-2.0.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-api-1.7.25.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/azure-data-lake-store-sdk-2.2.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/wildfly-openssl-1.0.4.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/slf4j-log4j12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/log4j-api-2.8.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-nfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-httpfs-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-native-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/hadoop-hdfs-client-3.0.0-cdh6.3.2-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/accessors-smart-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/audience-annotations-0.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/avro-1.8.2-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-beanutils-1.9.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/asm-5.0.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-codec-1.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-collections-3.2.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-compress-1.18.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-configuration2-2.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang3-3.7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpclient-4.5.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/httpcore-4.4.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-client-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-framework-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/curator-recipes-2.12.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okhttp-2.7.5.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-core-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-pkix-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-databind-2.9.9.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13-cloudera.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jackson-xc-1.9.13.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.activation-api-1.2.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-io-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jcip-annotations-1.0-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-core-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jaxb-api-2.2.11.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-server-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-servlet-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-smart-2.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-http-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-io-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-security-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-server-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-servlet-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-util-ajax-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-webapp-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jetty-xml-9.3.25.v20180904.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/json-simple-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/xz-1.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr311-api-1.1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-client-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-common-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-admin-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-crypto-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-identity-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-server-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-simplekdc-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jersey-json-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-config-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/jsch-0.1.54.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerb-util-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-xdr-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/netty-3.10.6.Final.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/okio-1.6.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/paranamer-2.8.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/stax2-api-3.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/snappy-java-1.1.4.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/zookeeper-3.4.5-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/woodstox-core-5.0.3.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/kerby-asn1-1.0.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-hdfs/lib/re2j-1.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-api-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-tests-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-router-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-registry-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-client-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-common-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-3.0.0-cdh6.3.2.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-json-provider-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/ehcache-3.3.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/metrics-core-3.0.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/bcprov-jdk15on-1.60.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/objenesis-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/json-io-2.5.1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-client-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-module-jaxb-annotations-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/HikariCP-java7-2.4.12.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/spark-2.4.0-cdh6.3.2-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jackson-jaxrs-base-2.9.9.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/jersey-guice-1.19.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/fst-2.50.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-servlet-4.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/java-util-1.9.0.jar:/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/lib/hadoop-yarn/lib/guice-4.0.jar
2021-04-07 19:01:00,366 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.io.tmpdir=/tmp
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:java.compiler=<NA>
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.name=Linux
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.arch=amd64
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:os.version=3.10.0-957.el7.x86_64
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.name=yarn
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.home=/var/lib/hadoop-yarn
2021-04-07 19:01:00,367 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Client environment:user.dir=/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/container_e06_1616661788395_0876_01_000004
2021-04-07 19:01:00,368 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ZooKeeper [] - Initiating client connection, connectString=sdl-hadoop1:2181,sdl-hadoop2:2181,sdl-hadoop3:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState@3359c978
2021-04-07 19:01:00,383 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.imps.CuratorFrameworkImpl [] - Default schema
2021-04-07 19:01:00,385 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: sdl-hadoop3.test.com.
2021-04-07 19:01:00,386 WARN  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - SASL configuration failed: javax.security.auth.login.LoginException: No JAAS configuration section named 'Client' was found in specified JAAS configuration file: '/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/jaas-6049651361304051356.conf'. Will continue connection to Zookeeper server without SASL authentication, if Zookeeper server allows it.
2021-04-07 19:01:00,388 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Opening socket connection to server sdl-hadoop3/192.168.32.191:2181
2021-04-07 19:01:00,389 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Socket connection established to sdl-hadoop3/192.168.32.191:2181, initiating session
2021-04-07 19:01:00,390 ERROR org.apache.flink.shaded.curator4.org.apache.curator.ConnectionState [] - Authentication failed
2021-04-07 19:01:00,390 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address sdl-hadoop3.test.com:0, bind address 0.0.0.0:0.
2021-04-07 19:01:00,396 INFO  org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn [] - Session establishment complete on server sdl-hadoop3/192.168.32.191:2181, sessionid = 0x175e3324a4e498b, negotiated timeout = 40000
2021-04-07 19:01:00,399 INFO  org.apache.flink.shaded.curator4.org.apache.curator.framework.state.ConnectionStateManager [] - State change: CONNECTED
2021-04-07 19:01:01,223 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-04-07 19:01:01,257 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-04-07 19:01:01,420 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@sdl-hadoop3.test.com:14391]
2021-04-07 19:01:01,700 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@sdl-hadoop3.test.com:14391
2021-04-07 19:01:01,724 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2021-04-07 19:01:01,727 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address sdl-hadoop3.test.com:0, bind address 0.0.0.0:0.
2021-04-07 19:01:01,742 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2021-04-07 19:01:01,747 INFO  akka.remote.Remoting                                         [] - Starting remoting
2021-04-07 19:01:01,767 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@sdl-hadoop3.test.com:7105]
2021-04-07 19:01:01,803 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@sdl-hadoop3.test.com:7105
2021-04-07 19:01:01,817 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_container_e06_1616661788395_0876_01_000004 .
2021-04-07 19:01:01,829 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/blobStore-2766b55c-85c1-4a24-84d0-b63e3a688039
2021-04-07 19:01:01,832 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/blobStore-8ad27967-f862-406d-9ddc-81011b3e682e
2021-04-07 19:01:01,835 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2021-04-07 19:01:01,835 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2021-04-07 19:01:01,835 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: container_e06_1616661788395_0876_01_000004(sdl-hadoop3.test.com:8041)
2021-04-07 19:01:01,867 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3698 GB (99.33% usable)
2021-04-07 19:01:01,867 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3698 GB (99.33% usable)
2021-04-07 19:01:01,867 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876': total 3723 GB, usable 3697 GB (99.30% usable)
2021-04-07 19:01:01,871 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-3bb0ba26-80b1-4280-b6f2-46b454b53cd0 for spill files.
2021-04-07 19:01:01,871 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-17122e36-aa01-45a1-9687-9a2f60d05579 for spill files.
2021-04-07 19:01:01,871 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-a154ef42-b678-4e8b-b77c-3355cd2ef79f for spill files.
2021-04-07 19:01:01,880 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: /0.0.0.0, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 3 (manual), number of client threads: 3 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2021-04-07 19:01:01,883 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-e3ffafdc-3aae-4be9-aeb6-a1798c1fe5e0 for spill files.
2021-04-07 19:01:01,883 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-be63cafc-c465-4a05-a941-84b9d26bf0a0 for spill files.
2021-04-07 19:01:01,883 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-595b1f01-2d58-41a5-8088-003b132973d0 for spill files.
2021-04-07 19:01:02,776 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 1024 MB for network buffer pool (number of memory segments: 32768, bytes per segment: 32768).
2021-04-07 19:01:02,789 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2021-04-07 19:01:02,856 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2021-04-07 19:01:02,858 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 69 ms).
2021-04-07 19:01:02,864 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2021-04-07 19:01:02,910 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 49 ms). Listening on SocketAddress /0.0.0.0:13594.
2021-04-07 19:01:02,911 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2021-04-07 19:01:02,942 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2021-04-07 19:01:03,010 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/resource_manager_lock'}.
2021-04-07 19:01:03,012 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2021-04-07 19:01:03,014 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-73554e82-0ded-4c36-9ea7-788b29b573a6
2021-04-07 19:01:03,014 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-36626715-50b0-4f24-9b6d-bf729853f028
2021-04-07 19:01:03,014 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-dist-cache-a30926ca-cb0f-4bae-8b0f-b8eddce6df0d
2021-04-07 19:01:03,037 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/resourcemanager_0(a38ce14622d89070e0a262795a77418b).
2021-04-07 19:01:03,258 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2021-04-07 19:01:03,310 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/resourcemanager_0 under registration id 7a7ce8d1544dd673af00cf8a373891e9.
2021-04-07 19:01:03,327 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 5a08ddc93177dc0d9bba37854e2e9e52 for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,334 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:03,335 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job e6687ed64b39d3f73366d371bd24dd3a for job leader monitoring.
2021-04-07 19:01:03,337 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/e6687ed64b39d3f73366d371bd24dd3a/job_manager_lock'}.
2021-04-07 19:01:03,341 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/jobmanager_2 with leader id b4741056-b894-4a34-b270-f7625ffded0b.
2021-04-07 19:01:03,343 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request da74afc930fd0e9effb4bb42d708c458 for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,343 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:03,344 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 2debaa3c820d564ff6fb0d492da0848d for job e6687ed64b39d3f73366d371bd24dd3a from resource manager with leader id a38ce14622d89070e0a262795a77418b.
2021-04-07 19:01:03,345 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:03,360 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2021-04-07 19:01:03,378 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@sdl-hadoop1.test.com:22255/user/rpc/jobmanager_2 for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,379 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,383 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:03,411 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:03,445 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77), deploy into slot with allocation id 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:03,445 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,453 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77) [DEPLOYING].
2021-04-07 19:01:03,454 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:03,458 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc), deploy into slot with allocation id da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:03,459 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,460 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:03,459 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc) [DEPLOYING].
2021-04-07 19:01:03,460 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:03,460 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:03,462 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:03,466 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9), deploy into slot with allocation id 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:03,466 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9) switched from CREATED to DEPLOYING.
2021-04-07 19:01:03,467 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9) [DEPLOYING].
2021-04-07 19:01:03,476 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc) [DEPLOYING].
2021-04-07 19:01:03,476 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77) [DEPLOYING].
2021-04-07 19:01:03,476 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9) [DEPLOYING].
2021-04-07 19:01:03,493 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,493 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,493 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:03,495 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,495 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,495 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:03,550 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,550 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,550 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:03,563 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:03,563 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:03,563 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:04,028 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,028 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,028 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:04,109 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9) switched from RUNNING to FINISHED.
2021-04-07 19:01:04,109 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc) switched from RUNNING to FINISHED.
2021-04-07 19:01:04,109 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 (11e9e2d98a51fdf79236be55b924d6c9).
2021-04-07 19:01:04,109 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 (49b27e61c00467888def1f39c4b2f3cc).
2021-04-07 19:01:04,113 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (3/3)#0 11e9e2d98a51fdf79236be55b924d6c9.
2021-04-07 19:01:04,121 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (2/3)#0 49b27e61c00467888def1f39c4b2f3cc.
2021-04-07 19:01:04,169 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:04,173 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b), deploy into slot with allocation id 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:04,173 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b) switched from CREATED to DEPLOYING.
2021-04-07 19:01:04,174 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b) [DEPLOYING].
2021-04-07 19:01:04,174 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b) [DEPLOYING].
2021-04-07 19:01:04,175 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:04,175 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:04,178 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:04,178 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:04,178 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:04,182 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf), deploy into slot with allocation id da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:04,183 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf) switched from CREATED to DEPLOYING.
2021-04-07 19:01:04,183 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf) [DEPLOYING].
2021-04-07 19:01:04,183 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf) [DEPLOYING].
2021-04-07 19:01:04,185 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:04,185 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:04,186 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:04,187 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:04,460 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,460 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,460 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:04,460 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:04,609 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77) switched from RUNNING to FINISHED.
2021-04-07 19:01:04,609 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 (3db93d33e3d3852001319421f3e98b77).
2021-04-07 19:01:04,611 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation]], fields=[id, gender, status]) -> Calc(select=[id, gender], where=[(status >= 0)]) (1/3)#0 3db93d33e3d3852001319421f3e98b77.
2021-04-07 19:01:04,647 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:04,650 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428), deploy into slot with allocation id 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:04,651 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428) switched from CREATED to DEPLOYING.
2021-04-07 19:01:04,651 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428) [DEPLOYING].
2021-04-07 19:01:04,652 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428) [DEPLOYING].
2021-04-07 19:01:04,652 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:04,652 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:04,653 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:04,654 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:04,756 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:04,756 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-files/dags/dags
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-files/dags/dags
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - PYTHONPATH of python worker: /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-files/dags/dags
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives
2021-04-07 19:01:06,409 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python working dir of python worker: /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives
2021-04-07 19:01:18,034 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:18,183 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:18,468 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:18,566 INFO  org.apache.flink.python.env.beam.ProcessPythonEnvironmentManager [] - Python interpreter path: conda.zip/conda/bin/python
2021-04-07 19:01:18,580 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:18,675 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:22,469 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:22,482 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:22,482 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 3-1
2021-04-07 19:01:22,483 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:22,484 WARN  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:22,485 WARN  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--app_name=BeamPythonFunctionRunner', '--options_id=2.0'] 
2021-04-07 19:01:22,485 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:22,486 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:22,486 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:8493.
2021-04-07 19:01:22,488 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:12995
2021-04-07 19:01:22,489 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:22,491 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:22,502 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:22,510 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:22,511 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:22,513 WARN  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:22,514 WARN  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--options_id=0.0', '--app_name=BeamPythonFunctionRunner'] 
2021-04-07 19:01:22,516 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:22,518 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:22,519 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:10537.
2021-04-07 19:01:22,519 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 1-1
2021-04-07 19:01:22,520 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:5189
2021-04-07 19:01:22,521 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:22,523 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:22,692 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:22,693 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:22,695 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:22,695 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:22,699 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:22,699 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:22,745 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=  , field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}]
2021-04-07 19:01:22,745 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=  , field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}]
2021-04-07 19:01:22,772 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2021-04-07 19:01:22,772 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2021-04-07 19:01:23,070 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/2:191607+30214]
2021-04-07 19:01:23,087 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 1-2
2021-04-07 19:01:23,092 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/3:0+209524]
2021-04-07 19:01:23,097 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:726 [] - Creating insecure state channel for localhost:15772.
2021-04-07 19:01:23,097 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 3-2
2021-04-07 19:01:23,098 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:733 [] - State channel established.
2021-04-07 19:01:23,099 INFO  /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-94c91313-c484-4d8c-ba56-87763744fded/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/data_plane.py:636 [] - Creating client data channel for localhost:19748
2021-04-07 19:01:23,103 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:726 [] - Creating insecure state channel for localhost:2399.
2021-04-07 19:01:23,104 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:733 [] - State channel established.
2021-04-07 19:01:23,107 INFO  /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-a973634f-220b-4df0-aa56-8613a3767bbb/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/data_plane.py:636 [] - Creating client data channel for localhost:7662
2021-04-07 19:01:23,107 INFO  org.apache.beam.runners.fnexecution.data.GrpcDataService     [] - Beam Fn Data client connected.
2021-04-07 19:01:23,110 INFO  org.apache.beam.runners.fnexecution.data.GrpcDataService     [] - Beam Fn Data client connected.
2021-04-07 19:01:23,123 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/2:191607+30214]
2021-04-07 19:01:23,123 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 3-3
2021-04-07 19:01:23,123 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - getProcessBundleDescriptor request with id 1-3
2021-04-07 19:01:23,123 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 0 because it is idle.
2021-04-07 19:01:23,123 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2021-04-07 19:01:23,123 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2021-04-07 19:01:23,129 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=  , field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}]
2021-04-07 19:01:23,130 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 1
2021-04-07 19:01:23,130 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/3:0+209524]
2021-04-07 19:01:23,131 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 0 because it is idle.
2021-04-07 19:01:23,131 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2021-04-07 19:01:23,131 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2021-04-07 19:01:23,136 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [HiveSourceSplit{hiveTablePartition=HiveTablePartition{storageDescriptor=StorageDescriptor(cols:[FieldSchema(name:bustype, type:int, comment:null), FieldSchema(name:ts, type:bigint, comment:null), FieldSchema(name:dataobj, type:string, comment:null)], location:hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=	, line.delim=
, field.delim=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionSpec={ds=2021-04-01}, tableProps={location=hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log, sink.partition-commit.delay=0, transient_lastDdlTime=1607308194, columns=bustype,ts,dataobj, file.outputformat=org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat, is_generic=false, file.inputformat=org.apache.hadoop.mapred.TextInputFormat, columns.comments=  , field.delim=	, name=chloe.chloe_bus_hive_log, serialization.lib=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, partition.time-extractor.timestamp-pattern=$ds, columns.types=int:bigint:string, sink.partition-commit.policy.kind=metastore,success-file, sink.partition-commit.trigger=process-time, bucket_count=-1, line.delim=
, partition_columns.types=string, EXTERNAL=TRUE, serialization.ddl=struct chloe_bus_hive_log { i32 bustype, i64 ts, string dataobj}, serialization.format=	, partition_columns=ds}}}]
2021-04-07 19:01:23,136 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 1
2021-04-07 19:01:23,176 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/1:0+143478]
2021-04-07 19:01:23,177 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/1:0+143478]
2021-04-07 19:01:23,178 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 1 because it is idle.
2021-04-07 19:01:23,178 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 1
2021-04-07 19:01:23,178 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 1 exited.
2021-04-07 19:01:23,185 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:23,185 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Finished reading from splits [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/2:0+191607]
2021-04-07 19:01:23,188 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Finished reading split(s) [hdfs://jcn1/user/hive/warehouse/chloe.db/chloe_bus_hive_log/ds=2021-04-01/2:0+191607]
2021-04-07 19:01:23,188 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager [] - Closing splitFetcher 1 because it is idle.
2021-04-07 19:01:23,188 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 1
2021-04-07 19:01:23,188 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 1 exited.
2021-04-07 19:01:23,194 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:23,255 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:23,255 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:24,084 INFO  org.apache.beam.runners.fnexecution.environment.ProcessEnvironmentFactory [] - Still waiting for startup of environment '/space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/pyflink/bin/pyflink-udf-runner.sh' for worker id 2-1
2021-04-07 19:01:24,095 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,095 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,095 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 (10fc33e7c257c3507db40c1a73d1d428).
2021-04-07 19:01:24,095 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 (507fdfb89ca84afd88edcea5ec275fbf).
2021-04-07 19:01:24,098 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (3/3)#0 10fc33e7c257c3507db40c1a73d1d428.
2021-04-07 19:01:24,106 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (2/3)#0 507fdfb89ca84afd88edcea5ec275fbf.
2021-04-07 19:01:24,108 INFO  org.apache.beam.runners.fnexecution.logging.GrpcLoggingService [] - Beam Fn Logging client connected.
2021-04-07 19:01:24,124 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:98 [] - Logging handler created.
2021-04-07 19:01:24,125 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:125 [] - semi_persistent_directory: /tmp
2021-04-07 19:01:24,126 WARN  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:240 [] - No session file found: /tmp/staged/pickled_main_session. Functions defined in __main__ (interactive session) may fail. 
2021-04-07 19:01:24,127 WARN  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/options/pipeline_options.py:309 [] - Discarding unparseable args: ['--options_id=1.0', '--app_name=BeamPythonFunctionRunner'] 
2021-04-07 19:01:24,128 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:138 [] - Python sdk harness started with pipeline_options: {}
2021-04-07 19:01:24,129 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/statecache.py:154 [] - Creating state cache with size 0
2021-04-07 19:01:24,130 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:155 [] - Creating insecure control channel for localhost:24442.
2021-04-07 19:01:24,130 INFO  org.apache.beam.runners.fnexecution.control.FnApiControlClientPoolService [] - Beam Fn Control client connected with id 2-1
2021-04-07 19:01:24,131 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker_main.py:79 [] - Status HTTP server running at localhost.localdomain:9889
2021-04-07 19:01:24,132 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:163 [] - Control channel established.
2021-04-07 19:01:24,133 INFO  /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/python-dist-b4ddbff0-0d0b-419e-82c5-078be7ed366e/python-archives/conda.zip/conda/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py:203 [] - Initializing SDKHarness with unbounded number of workers.
2021-04-07 19:01:24,133 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:24,139 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0), deploy into slot with allocation id 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:24,139 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,139 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0) [DEPLOYING].
2021-04-07 19:01:24,141 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,142 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0) [DEPLOYING].
2021-04-07 19:01:24,143 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,143 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,143 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c), deploy into slot with allocation id da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,143 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,144 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c) [DEPLOYING].
2021-04-07 19:01:24,145 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c) [DEPLOYING].
2021-04-07 19:01:24,146 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,146 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,149 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,150 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,150 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,150 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,161 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle size is configured to 100000.
2021-04-07 19:01:24,162 INFO  org.apache.flink.streaming.api.operators.AbstractStreamOperator [] - The maximum bundle time is configured to 1000 milliseconds.
2021-04-07 19:01:24,166 INFO  org.apache.flink.streaming.api.runners.python.beam.BeamPythonFunctionRunner [] - Obtained shared Python process of size 6362619452 bytes
2021-04-07 19:01:24,184 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,184 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,196 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,196 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 (2d188c526124c9418897de997d30e97c).
2021-04-07 19:01:24,199 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (2/3)#0 2d188c526124c9418897de997d30e97c.
2021-04-07 19:01:24,201 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Reader received NoMoreSplits event.
2021-04-07 19:01:24,202 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2021-04-07 19:01:24,205 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,205 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 (40932812548289b1e5bb4a2eae6a132b).
2021-04-07 19:01:24,205 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: HiveSource-chloe.chloe_bus_hive_log -> Calc(select=[dataobj], where=[(bustype = 12)]) -> (BatchExecPythonCalc, BatchExecPythonCalc) (1/3)#0 40932812548289b1e5bb4a2eae6a132b.
2021-04-07 19:01:24,208 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,210 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833), deploy into slot with allocation id da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,211 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,211 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833) [DEPLOYING].
2021-04-07 19:01:24,212 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833) [DEPLOYING].
2021-04-07 19:01:24,212 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,212 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,213 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,214 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,219 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,229 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:24,231 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,231 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 (e54c122b2777f25b83e4d04854a83833).
2021-04-07 19:01:24,249 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df), deploy into slot with allocation id 2debaa3c820d564ff6fb0d492da0848d.
2021-04-07 19:01:24,249 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,249 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (3/3)#0 e54c122b2777f25b83e4d04854a83833.
2021-04-07 19:01:24,249 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) [DEPLOYING].
2021-04-07 19:01:24,250 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) [DEPLOYING].
2021-04-07 19:01:24,250 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,250 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,253 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,255 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,259 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,261 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1), deploy into slot with allocation id da74afc930fd0e9effb4bb42d708c458.
2021-04-07 19:01:24,262 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,262 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) [DEPLOYING].
2021-04-07 19:01:24,263 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) [DEPLOYING].
2021-04-07 19:01:24,264 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,264 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,266 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,266 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,283 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,283 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,308 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,308 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,348 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0) switched from RUNNING to FINISHED.
2021-04-07 19:01:24,348 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 (39373a970bfd75ab2bf539f8ffdeb9e0).
2021-04-07 19:01:24,349 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task Source: TableSourceScan(table=[[myhive, chloe, face_shop_collocation, project=[id, status]]], fields=[id, status]) -> Calc(select=[id], where=[(status >= 0)]) (1/3)#0 39373a970bfd75ab2bf539f8ffdeb9e0.
2021-04-07 19:01:24,358 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:24,360 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e), deploy into slot with allocation id 5a08ddc93177dc0d9bba37854e2e9e52.
2021-04-07 19:01:24,360 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e) switched from CREATED to DEPLOYING.
2021-04-07 19:01:24,360 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e) [DEPLOYING].
2021-04-07 19:01:24,361 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e) [DEPLOYING].
2021-04-07 19:01:24,361 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_file_1b16836ad75b4815a386cfc7d2d3e732c547611c15eee6d2a0ecfa175a66731a'.
2021-04-07 19:01:24,361 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Obtaining local cache file for 'python_archive_4d1c691195befdd87b7e3677d2cf9f1fbfc70187c8a2a4483baffcd6fbe22e0b'.
2021-04-07 19:01:24,362 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'hdfs://jcn1/flink/1.12.2/checkpoints', savepoints: 'hdfs://jcn1/flink/1.12.2/savepoints', asynchronous: TRUE, maxStateSize: 5242880)
2021-04-07 19:01:24,362 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e) switched from DEPLOYING to RUNNING.
2021-04-07 19:01:24,367 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,368 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,371 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,371 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,371 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) exceeded the 80 characters length limit and was truncated.
2021-04-07 19:01:24,404 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:24,404 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:24,404 INFO  org.apache.flink.table.runtime.hashtable.BaseHybridHashTable [] - Initialize hash table with 194171 memory segments, each size [32768], the memory 6067 MB.
2021-04-07 19:01:27,415 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e) switched from RUNNING to FAILED.
java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
2021-04-07 19:01:27,427 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 (acc0759fada1f8a28b8fe4d6fba40d2e).
2021-04-07 19:01:27,435 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (3/3)#0 acc0759fada1f8a28b8fe4d6fba40d2e.
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df).
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) switched from RUNNING to CANCELING.
2021-04-07 19:01:27,524 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df).
2021-04-07 19:01:27,678 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1).
2021-04-07 19:01:27,679 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 is already in state FAILED
2021-04-07 19:01:27,677 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1) switched from RUNNING to FAILED.
java.lang.RuntimeException: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:84) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.getNextBuffer(BaseHybridHashTable.java:254) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.BaseHybridHashTable.nextSegment(BaseHybridHashTable.java:313) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:166) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHashPartition.<init>(LongHashPartition.java:136) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.createPartitions(LongHybridHashTable.java:276) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.hashtable.LongHybridHashTable.<init>(LongHybridHashTable.java:89) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	at LongHashJoinOperator$893$LongHashTable$877.<init>(Unknown Source) ~[?:?]
	at LongHashJoinOperator$893.open(Unknown Source) ~[?:?]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:428) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$beforeInvoke$2(StreamTask.java:543) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:533) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:573) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:755) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:570) [flink-dist_2.12-1.12.2.jar:1.12.2]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_181]
Caused by: org.apache.flink.runtime.memory.MemoryAllocationException: Could not allocate 512 pages
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:235) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
Caused by: org.apache.flink.runtime.memory.MemoryReservationException: Could not allocate 16777216 bytes, only 0 bytes are remaining. This usually indicates that you are requesting more memory than you have reserved. However, when running an old JVM version it can also be caused by slow garbage collection. Try to upgrade to Java 8u72 or higher if running on an old Java version.
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:170) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.UnsafeMemoryBudget.reserveMemory(UnsafeMemoryBudget.java:84) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.runtime.memory.MemoryManager.allocatePages(MemoryManager.java:232) ~[flink-dist_2.12-1.12.2.jar:1.12.2]
	at org.apache.flink.table.runtime.util.LazyMemorySegmentPool.nextSegment(LazyMemorySegmentPool.java:82) ~[flink-table-blink_2.12-1.12.2.jar:1.12.2]
	... 16 more
2021-04-07 19:01:27,680 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 (8578cde024ae2ee475feacd982189cc1).
2021-04-07 19:01:27,682 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (2/3)#0 8578cde024ae2ee475feacd982189cc1.
2021-04-07 19:01:28,701 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df) switched from CANCELING to CANCELED.
2021-04-07 19:01:28,701 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 (0d7ec821946a5183b4b8ad7915c212df).
2021-04-07 19:01:28,703 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task HashJoin(joinType=[InnerJoin], where=[(item_id = id)], select=[item_id, user_id, source, id, gender], build=[left]) -> Calc(select=[(_UTF-16LE'_' CONCAT_WS source CONCAT_WS CAST(gender)) AS group_key, user_id]) -> Expand(projects=[group_key, user_id, $e, user_id_0], projects=[{group_key, user_id, 0 AS $e, user_id AS user_id_0}, {group_key, null AS user_id, 1 AS $e, user_id AS user_id_0}]) (1/3)#0 0d7ec821946a5183b4b8ad7915c212df.
2021-04-07 19:01:28,754 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: 5a08ddc93177dc0d9bba37854e2e9e52, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:28,962 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: da74afc930fd0e9effb4bb42d708c458, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:29,140 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:2, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=8.472gb (9096536515 bytes), taskOffHeapMemory=0 bytes, managedMemory=5.926gb (6362619452 bytes), networkMemory=341.333mb (357913941 bytes)}, allocationId: 2debaa3c820d564ff6fb0d492da0848d, jobId: e6687ed64b39d3f73366d371bd24dd3a).
2021-04-07 19:01:29,294 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job e6687ed64b39d3f73366d371bd24dd3a from job leader monitoring.
2021-04-07 19:01:29,294 INFO  org.apache.flink.runtime.leaderretrieval.DefaultLeaderRetrievalService [] - Stopping DefaultLeaderRetrievalService.
2021-04-07 19:01:29,294 INFO  org.apache.flink.runtime.leaderretrieval.ZooKeeperLeaderRetrievalDriver [] - Closing ZookeeperLeaderRetrievalDriver{retrievalPath='/leader/e6687ed64b39d3f73366d371bd24dd3a/job_manager_lock'}.
2021-04-07 19:01:29,295 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job e6687ed64b39d3f73366d371bd24dd3a.
2021-04-07 19:01:30,470 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2021-04-07 19:01:30,470 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2021-04-07 19:01:30,471 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2021-04-07 19:01:30,474 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2021-04-07 19:01:30,474 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection d39dd16b04f7cfeb68b2bc47f8845e3d.
2021-04-07 19:01:30,476 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-e3ffafdc-3aae-4be9-aeb6-a1798c1fe5e0
2021-04-07 19:01:30,477 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space1/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-3bb0ba26-80b1-4280-b6f2-46b454b53cd0
2021-04-07 19:01:30,477 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-be63cafc-c465-4a05-a941-84b9d26bf0a0
2021-04-07 19:01:30,478 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space2/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-17122e36-aa01-45a1-9687-9a2f60d05579
2021-04-07 19:01:30,478 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-netty-shuffle-595b1f01-2d58-41a5-8088-003b132973d0
2021-04-07 19:01:30,478 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /space3/yarn/nm/usercache/root/appcache/application_1616661788395_0876/flink-io-a154ef42-b678-4e8b-b77c-3355cd2ef79f

End of LogType:taskmanager.log
********************************************************************************


End of LogType:taskmanager.out
********************************************************************************

