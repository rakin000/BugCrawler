{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bug_crawler.github_fetcher import fetch_github_issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dC8whvlAdFUz"
      },
      "outputs": [],
      "source": [
        "from bug_crawler.openai_client import call_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u_OT9Ce9b2fW"
      },
      "outputs": [],
      "source": [
        "# ------------------------\n",
        "# CONFIGURATION\n",
        "# ------------------------\n",
        "# https://github.com/elastic/elasticsearch\n",
        "OWNER = \"elastic\"         # GitHub username or org\n",
        "REPO = \"elasticsearch\"         # Repository name\n",
        "STATE = \"closed\"           # \"open\", \"closed\", or \"all\"\n",
        "PER_PAGE = 50            # Max 100 per page\n",
        "MAX_PAGES = 5           # How many pages to fetch (50*3 = 150 issues)\n",
        "TOKEN = None             # Put a GitHub Personal Access Token here (optional)\n",
        "start_date = \"2023-01-01\"  # ISO 8601 format, e.g. \"2023-10-01\"\n",
        "end_date = None # \"2025-09-30\"    # ISO 8601 format,\n",
        "keywords = \"slowdown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching issues using the Search API...\n",
            "\n",
            "Found 7 issues in the date range.\n",
            "  #135340: Possible performance regression in 9.1.x (TSDS) (Created: 2025-09-24T10:46:49Z)\n",
            "  #118623: Performance degradation after upgrading from 8.6.1 to 8.16.1 (Created: 2024-12-12T21:38:03Z)\n",
            "  #112781: Lazy data stream rollover is not triggered when using reroute (Created: 2024-09-12T02:47:46Z)\n",
            "  #102063: During data ingestion, significants amount of CPU and memory is used to parse date strings (>10% realistic for some workloads) (Created: 2023-11-13T10:26:27Z)\n",
            "  #101763: ESQL: unexpected count(*) query planning slowdown at scale (Created: 2023-11-03T08:30:36Z)\n",
            "  #99409: [Ml] CircuitBreakingException when deploying the ELSER model (Created: 2023-09-11T09:14:13Z)\n",
            "  #96349: Fetching many fields takes much more time than retrieving _source (Created: 2023-05-25T13:57:23Z)\n"
          ]
        }
      ],
      "source": [
        "print(\"Fetching issues using the Search API...\")\n",
        "try:\n",
        "    # Find issues created between Oct 1 and Oct 15, 2025\n",
        "    issues_in_range = fetch_github_issues(\n",
        "        owner=OWNER,\n",
        "        repo=REPO,\n",
        "        state=STATE,      # Search for closed issues\n",
        "        per_page=PER_PAGE,\n",
        "        max_pages=MAX_PAGES,\n",
        "        start_date=start_date,\n",
        "        end_date=end_date,\n",
        "        keywords=keywords,\n",
        "        token=TOKEN,\n",
        "        include_comments=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\nFound {len(issues_in_range)} issues in the date range.\")\n",
        "    for issue in issues_in_range:\n",
        "        print(f\"  #{issue['number']}: {issue['title']} (Created: {issue['created_at']})\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ypN5ieZgAfm",
        "outputId": "9bd0bf7f-5d33-4be0-d78c-25e20ce362f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "issues = issues_in_range\n",
        "len(issues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'number': 135340, 'title': 'Possible performance regression in 9.1.x (TSDS)', 'body': 'Hi, guys!\\n\\nOn a multi-node cluster, indexing of TSDS (otel-format metrics) is stable on 9.0.x.\\nAfter upgrading to 9.1.4, the indexing rate drops and the write queue grows, making the cluster unstable.\\n\\nProfiling shows significant time spent in dv.writeField (see pic. 1)\\nDisabling the new 9.1.x optimization with:\\n\\n```ini\\n-Dorg.elasticsearch.index.codec.tsdb.es819.ES819TSDBDocValuesConsumer.enableOptimizedMerge=false\\n```\\n\\nrestores normal performance.\\n\\n<img width=\"1879\" height=\"916\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0d519768-cc86-4113-83c9-9e7b6a253a2e\" />\\n\\n<img width=\"890\" height=\"517\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/5aecaa33-fc2b-4d70-bc54-20f9b2ea08c5\" />\\n<img width=\"922\" height=\"294\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/13c028f7-84ee-4ba9-b519-b8e945775432\" />\\n\\n\\nCan you help figure out the root cause?\\n\\n(using java 21)', 'user': 'sherman', 'state': 'closed', 'labels': ['>bug', 'Team:StorageEngine', 'priority:high', ':StorageEngine/Codec'], 'url': 'https://github.com/elastic/elasticsearch/issues/135340', 'created_at': '2025-09-24T10:46:49Z', 'comments': 11, 'repository_url': 'https://api.github.com/repos/elastic/elasticsearch', 'html_url': 'https://github.com/elastic/elasticsearch/issues/135340', 'comments_thread': [{'user': 'elasticsearchmachine', 'created_at': '2025-09-24T10:57:37Z', 'body': 'Pinging @elastic/es-storage-engine (Team:StorageEngine)'}, {'user': 'kkrik-es', 'created_at': '2025-09-24T12:00:22Z', 'body': 'Seems similar to https://github.com/elastic/elasticsearch/pull/132597 that should be fixed in v.9.1.2. @martijnvg @dnhatn fyi.'}, {'user': 'sherman', 'created_at': '2025-09-24T12:16:41Z', 'body': '@kkrik-es, hi!\\n\\nI’m using 9.1.4 (flamegraph from it), which already includes this patch.'}, {'user': 'martijnvg', 'created_at': '2025-09-24T12:37:29Z', 'body': \"Thanks @sherman for reporting this. Looks like closing a temporary index output is much slower than expected. We will take a look at get back to you.\\n\\nLooking at the `DISIAccumulator`, looks we close twice, while only once should be needed. I don't think this explains the regression, but that should also be addressed.\"}, {'user': 'martijnvg', 'created_at': '2025-09-24T18:49:14Z', 'body': \"We discussed this and we noticed the following:\\n\\n- The `DISIAccumulator` should only be used during merging, but it is also used here during the flush. This shouldn't happen and needs to be addressed.\\n- The tmp file it tries to create are mmap-ed, perhaps we this shouldn't be done in this case. Which could explain this slowdown under load. (not enough memory for OS to mmap all files and also not the tmp files that are being created) \"}, {'user': 'sherman', 'created_at': '2025-09-25T08:20:55Z', 'body': 'If you mean DISI temp files, I’m not sure they affect memory - they’re too small?\\n\\n```bash\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n15846\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n6234\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n11666\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n21302\\n```'}, {'user': 'sherman', 'created_at': '2025-09-25T14:54:17Z', 'body': 'I believe the main problem is not with file writes, but with file reads.\\nFrom what I see, when we read a file in DISIAccumulator, here:\\n\\n```java\\ntry (var addressDataInput = dir.openInput(skipListTempFileName, context)) {\\n    data.copyBytes(addressDataInput, addressDataInput.length());\\n}\\n```\\n\\n\\nit uses a memory-segment input implementation that relies on a shared arena.\\nOn Java 21, the close() method is very expensive (because it leads to deopts of top frames in each thread), and each file here gets its own shared arena. We also observed this in profiling.'}, {'user': 'dnhatn', 'created_at': '2025-09-25T20:58:53Z', 'body': '@sherman Thanks so much for providing more detailed insight. I think this is possible, given that writing and reading mmap files happens per field. What is your setting for `index.store.type`?'}, {'user': 'dnhatn', 'created_at': '2025-09-25T22:35:32Z', 'body': 'And the refresh interval setting `index.refresh_interval`'}, {'user': 'sherman', 'created_at': '2025-09-26T08:33:28Z', 'body': '@dnhatn Hi!\\n\\n```\\n\"mode\": \"time_series\",\\n\"refresh_interval\": \"10s\",\\n\\n \"store\": {\\n        \"stats_refresh_interval\": \"10s\",\\n        \"type\": \"\",\\n        \"fs\": {\\n          \"fs_lock\": \"native\"\\n        },\\n```\\n\\nIt’s a high-throughput data stream that writes large volumes of metrics in OTEL format.'}, {'user': 'martijnvg', 'created_at': '2025-09-26T09:52:29Z', 'body': '@sherman We have merged a change that we think will address the regression that you\\'ve reported. When you upgrade to the new bug fix release and the repression doesn\\'t resolve itself, then please feel free to re-open this issue. Thanks for bringing this regression to our attention.\\n\\n> \"refresh_interval\": \"10s\",\\n\\nIt is always good to re-evaluate the refresh interval. In the case of metrics, how often is the poll/collection interval and typically refresh should never be lower than the poll/collection interval. Secondly what are the refresh requirements. Is it acceptable to have a 30 second delay until new segments are visible.\\n\\nAlso do searches continuously happen during the day? Sometimes it is better to use the defaults. Given that the then periodic refresh doesn\\'t happen all the time and only on the first search the periodic refresh is enabled and stays around until a shard becomes search idle again.'}], 'comments_thread_text': 'Comment by elasticsearchmachine at 2025-09-24T10:57:37Z:\\nPinging @elastic/es-storage-engine (Team:StorageEngine)\\n\\nComment by kkrik-es at 2025-09-24T12:00:22Z:\\nSeems similar to https://github.com/elastic/elasticsearch/pull/132597 that should be fixed in v.9.1.2. @martijnvg @dnhatn fyi.\\n\\nComment by sherman at 2025-09-24T12:16:41Z:\\n@kkrik-es, hi!\\n\\nI’m using 9.1.4 (flamegraph from it), which already includes this patch.\\n\\nComment by martijnvg at 2025-09-24T12:37:29Z:\\nThanks @sherman for reporting this. Looks like closing a temporary index output is much slower than expected. We will take a look at get back to you.\\n\\nLooking at the `DISIAccumulator`, looks we close twice, while only once should be needed. I don\\'t think this explains the regression, but that should also be addressed.\\n\\nComment by martijnvg at 2025-09-24T18:49:14Z:\\nWe discussed this and we noticed the following:\\n\\n- The `DISIAccumulator` should only be used during merging, but it is also used here during the flush. This shouldn\\'t happen and needs to be addressed.\\n- The tmp file it tries to create are mmap-ed, perhaps we this shouldn\\'t be done in this case. Which could explain this slowdown under load. (not enough memory for OS to mmap all files and also not the tmp files that are being created) \\n\\nComment by sherman at 2025-09-25T08:20:55Z:\\nIf you mean DISI temp files, I’m not sure they affect memory - they’re too small?\\n\\n```bash\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n15846\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n6234\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n11666\\n[root@hssf86 elasticsearch]# lsof +p 2259807 | grep -i disi | tr -s \" \" | cut -d \" \" -f 7 | awk \\'{ sum += $1 } END { print sum }\\'\\n21302\\n```\\n\\nComment by sherman at 2025-09-25T14:54:17Z:\\nI believe the main problem is not with file writes, but with file reads.\\nFrom what I see, when we read a file in DISIAccumulator, here:\\n\\n```java\\ntry (var addressDataInput = dir.openInput(skipListTempFileName, context)) {\\n    data.copyBytes(addressDataInput, addressDataInput.length());\\n}\\n```\\n\\n\\nit uses a memory-segment input implementation that relies on a shared arena.\\nOn Java 21, the close() method is very expensive (because it leads to deopts of top frames in each thread), and each file here gets its own shared arena. We also observed this in profiling.\\n\\nComment by dnhatn at 2025-09-25T20:58:53Z:\\n@sherman Thanks so much for providing more detailed insight. I think this is possible, given that writing and reading mmap files happens per field. What is your setting for `index.store.type`?\\n\\nComment by dnhatn at 2025-09-25T22:35:32Z:\\nAnd the refresh interval setting `index.refresh_interval`\\n\\nComment by sherman at 2025-09-26T08:33:28Z:\\n@dnhatn Hi!\\n\\n```\\n\"mode\": \"time_series\",\\n\"refresh_interval\": \"10s\",\\n\\n \"store\": {\\n        \"stats_refresh_interval\": \"10s\",\\n        \"type\": \"\",\\n        \"fs\": {\\n          \"fs_lock\": \"native\"\\n        },\\n```\\n\\nIt’s a high-throughput data stream that writes large volumes of metrics in OTEL format.\\n\\nComment by martijnvg at 2025-09-26T09:52:29Z:\\n@sherman We have merged a change that we think will address the regression that you\\'ve reported. When you upgrade to the new bug fix release and the repression doesn\\'t resolve itself, then please feel free to re-open this issue. Thanks for bringing this regression to our attention.\\n\\n> \"refresh_interval\": \"10s\",\\n\\nIt is always good to re-evaluate the refresh interval. In the case of metrics, how often is the poll/collection interval and typically refresh should never be lower than the poll/collection interval. Secondly what are the refresh requirements. Is it acceptable to have a 30 second delay until new segments are visible.\\n\\nAlso do searches continuously happen during the day? Sometimes it is better to use the defaults. Given that the then periodic refresh doesn\\'t happen all the time and only on the first search the periodic refresh is enabled and stays around until a shard becomes search idle again.\\n'}\n"
          ]
        }
      ],
      "source": [
        "issue = issues[0]\n",
        "issue_text = f\"Title: {issue['title']}\\n\\nDescription: {issue['body']}\\n\\nComments: {issue.get('comments_thread_text', '')}\"\n",
        "print(issue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"bug_crawler/prompt_template/filter_application_resource.txt\", \"r\") as f:\n",
        "    FILTER_PROMPT = f.read()\n",
        "\n",
        "\n",
        "response = call_openai(FILTER_PROMPT.format(app_name='Elasticsearch', issue_text=issue_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"application_resource\": \"yes\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
